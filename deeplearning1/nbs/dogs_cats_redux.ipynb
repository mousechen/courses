{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs Cat Redux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, you will learn how generate and submit predictions to a Kaggle competiton\n",
    "\n",
    "[Dogs vs. Cats Redux: Kernels Edition](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start you will need to download and unzip the competition data from Kaggle and ensure your directory structure looks like this\n",
    "```\n",
    "utils/\n",
    "    vgg16.py\n",
    "    utils.py\n",
    "lesson1/\n",
    "    redux.ipynb\n",
    "    data/\n",
    "        redux/\n",
    "            train/\n",
    "                cat.437.jpg\n",
    "                dog.9924.jpg\n",
    "                cat.1029.jpg\n",
    "                dog.4374.jpg\n",
    "            test/\n",
    "                231.jpg\n",
    "                325.jpg\n",
    "                1235.jpg\n",
    "                9923.jpg\n",
    "```\n",
    "\n",
    "You can download the data files from the competition page [here](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data) or you can download them from the command line using the [Kaggle CLI](https://github.com/floydwch/kaggle-cli).\n",
    "\n",
    "You should launch your notebook inside the lesson1 directory\n",
    "```\n",
    "cd lesson1\n",
    "jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T00:48:50.571888Z",
     "start_time": "2018-07-04T00:48:50.547926Z"
    }
   },
   "outputs": [],
   "source": [
    "#Verify we are in the lesson1 directory\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T00:48:52.842256Z",
     "start_time": "2018-07-04T00:48:52.831291Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create references to important directories we will use over and over\n",
    "import os, sys\n",
    "current_dir = os.getcwd()\n",
    "LESSON_HOME_DIR = current_dir\n",
    "DATA_HOME_DIR = current_dir + \"\\data\\\\redux\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T00:48:59.873021Z",
     "start_time": "2018-07-04T00:48:56.517089Z"
    }
   },
   "outputs": [],
   "source": [
    "#Allow relative imports to directories above lesson1/\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "\n",
    "#import modules\n",
    "import imp\n",
    "import utils\n",
    "#imp.reload(utils)\n",
    "from utils import *\n",
    "#from vgg16 import Vgg16\n",
    "\n",
    "#Instantiate plotting tool\n",
    "#In Jupyter notebooks, you will need to run this command before doing any plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T00:52:08.606424Z",
     "start_time": "2018-07-04T00:52:08.593457Z"
    }
   },
   "outputs": [],
   "source": [
    "keras.backend.image_data_format() # 返回指定了 Keras 将遵循的数据格式约定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T01:02:40.233118Z",
     "start_time": "2018-07-04T01:02:39.692276Z"
    }
   },
   "outputs": [],
   "source": [
    "# 自己定义一个Vgg16的类，封装起来。\n",
    "\n",
    "import os, json\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from scipy import misc, ndimage\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input,Dense,Activation,ZeroPadding2D,Dropout,Conv2D,MaxPool2D,Flatten,Lambda,BatchNormalization\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# In case we are going to use the TensorFlow backend we need to explicitly set the Theano image ordering\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "\n",
    "\n",
    "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((3,1,1))\n",
    "def vgg_preprocess(x):\n",
    "    \"\"\"\n",
    "        Subtracts the mean RGB value, and transposes RGB to BGR.\n",
    "        The mean RGB was computed on the image set used to train the VGG model.\n",
    "\n",
    "        Args: \n",
    "            x: Image array (height x width x channels)\n",
    "        Returns:\n",
    "            Image array (height x width x transposed_channels)\n",
    "    \"\"\"\n",
    "    x = x - vgg_mean\n",
    "    return x[:, ::-1] # reverse axis rgb->bgr\n",
    "\n",
    "\n",
    "class Vgg16():\n",
    "    \n",
    "    \"\"\"\n",
    "    Vgg 16模型实现\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.FILES_PATH = 'http://files.fast.ai/models/'\n",
    "        self.create()\n",
    "        self.get_classes()\n",
    "       \n",
    "        \n",
    "    def get_classes(self):\n",
    "        \"\"\"\n",
    "        下载Imagenet的图片分类，存在缓冲中目录为.keras\n",
    "        \"\"\"\n",
    "        # 暂时使用fast.ai的目录\n",
    "        fname='imagenet_class_index.json'\n",
    "\n",
    "        fpath = get_file(fname,self.FILES_PATH+fname,cache_dir='models')\n",
    "        with open(fpath) as f:\n",
    "            class_dict = json.load(f)\n",
    "        self.classes = [class_dict[str(i)][1] for i in range(len(class_dict))]\n",
    "        \n",
    "    def predict(self,imgs,detail=False):\n",
    "        \"\"\"\n",
    "            Predict the labels of a set of images using the VGG16 model.\n",
    "\n",
    "            Args:\n",
    "                imgs (ndarray)    : An array of N images (size: N x width x height x channels).\n",
    "                details : ??\n",
    "            \n",
    "            Returns:\n",
    "                preds (np.array) : Highest confidence value of the predictions for each image.\n",
    "                idxs (np.ndarray): Class index of the predictions with the max confidence.\n",
    "                classes (list)   : Class labels of the predictions with the max confidence.\n",
    "        \"\"\"\n",
    "        \n",
    "        all_preds = self.model.predict(imgs)\n",
    "        print(all_preds)\n",
    "        idxs = np.argmax(all_preds,axis=1)\n",
    "        preds = [all_preds[i,idxs[i]] for i in range(len(idxs))]\n",
    "        classes = [self.classes[idx] for idx in idxs]\n",
    "        return np.array(preds),idxs,classes\n",
    "    \n",
    "    def ConvBlock(self,n_layers,n_filters):\n",
    "        \"\"\"\n",
    "            Adds a specified number of ZeroPadding and Covolution layers\n",
    "            to the model, and a MaxPooling layer at the very end.\n",
    "\n",
    "            Args:\n",
    "                layers (int):   The number of zero padded convolution layers\n",
    "                                to be added to the model.\n",
    "                filters (int):  The number of convolution filters to be \n",
    "                                created for each layer.\n",
    "        \"\"\"\n",
    "        model = self.model\n",
    "        for layer in range(n_layers):\n",
    "            model.add(ZeroPadding2D(padding=(1,1)))\n",
    "            model.add(Conv2D(filters=n_filters,kernel_size=(3,3),strides=(1,1),activation='relu',data_format='channels_first'))\n",
    "        model.add(MaxPool2D(pool_size=(2,2),strides=(2,2),data_format='channels_first'))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def FcBlock(self):\n",
    "        \"\"\"\n",
    "            Adds a fully connected layer of 4096 neurons to the model with a\n",
    "            Dropout of 0.5\n",
    "\n",
    "            Args:   None\n",
    "            Returns:   None\n",
    "        \"\"\"\n",
    "        model = self.model\n",
    "        model.add(Dense(4096,activation='relu')) # FC1\n",
    "        model.add(Dropout(rate=0.5))\n",
    "        \n",
    "    def create(self):\n",
    "        \"\"\"\n",
    "            Creates the VGG16 network achitecture and loads the pretrained weights.\n",
    "\n",
    "            Args:   None\n",
    "            Returns:   None\n",
    "        \"\"\"\n",
    "        model = self.model = Sequential()\n",
    "        #  顺序 (Sequential) 模型写法第一add 必须加input_shape\n",
    "        model.add(Lambda(vgg_preprocess, input_shape=(3,224,224), output_shape=(3,224,224)))\n",
    "\n",
    "        self.ConvBlock(2,64) # 最开始的2层用64个3x3的过滤器，然后pool\n",
    "        self.ConvBlock(2,128)\n",
    "        self.ConvBlock(3,256)\n",
    "        self.ConvBlock(3,512)\n",
    "        self.ConvBlock(3,512)\n",
    "\n",
    "        model.add(Flatten()) # 拉平，展开\n",
    "        self.FcBlock()\n",
    "        self.FcBlock()\n",
    "        model.add(Dense(1000,activation='softmax')) # 1000个分类\n",
    "        \n",
    "        # 读取预训练好的模型权重\n",
    "        fpath = get_file('vgg16.h5', self.FILES_PATH+'vgg16.h5', cache_subdir='models') # 读取训练好的权重\n",
    "        \n",
    "        model.load_weights(fpath)\n",
    "        \n",
    "            \n",
    "    def get_batches(self,path,gen = image.ImageDataGenerator(),class_mode='categorical',batch_size=4,shuffle=True):\n",
    "        \"\"\"\n",
    "            Takes the path to a directory, and generates batches of augmented/normalized data. Yields batches indefinitely, in an infinite loop.\n",
    "\n",
    "            See Keras documentation: https://keras.io/preprocessing/image/\n",
    "        \"\"\"\n",
    "        return gen.flow_from_directory(path,target_size=(224,224),\n",
    "                                   class_mode=class_mode,batch_size=batch_size,shuffle=shuffle)\n",
    "    \n",
    "            \n",
    "    def ft(self,n_neurons):\n",
    "        \"\"\"\n",
    "            冻结vgg16出去最后一层softmax 1000的全连接层，改为 传递进去的神经元个数\n",
    "            Replace the last layer of the model with a Dense (fully connected) layer of num neurons.\n",
    "            Will also lock the weights of all layers except the new layer so that we only learn\n",
    "            weights for the last layer in subsequent training.\n",
    "\n",
    "            Args:\n",
    "                num (int) : Number of neurons in the Dense layer\n",
    "            Returns:\n",
    "                None\n",
    "        \"\"\"\n",
    "        model = self.model\n",
    "        model.pop()\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = False # 这些层不训练\n",
    "        model.add(Dense(n_neurons,activation='softmax'))\n",
    "        self.compile()\n",
    "        \n",
    "        \n",
    "    \n",
    "    def finetune(self,batches):\n",
    "        \"\"\"\n",
    "            # 微调模型,更新self.classes 不同的数据需要变动这里。\n",
    "            Modifies the original VGG16 network architecture and updates self.classes for new training data.\n",
    "            \n",
    "            Args:\n",
    "                batches : A keras.preprocessing.image.ImageDataGenerator object.\n",
    "                          See definition for get_batches().\n",
    "        \"\"\"\n",
    "        self.ft(batches.num_classes) # 获得数据的类别个数\n",
    "        classes = list(iter(batches.class_indices)) # get a list of all the class labels\n",
    "        \n",
    "        # batches.class_indices is a dict with the class name as key and an index as value\n",
    "        # eg. {'cats': 0, 'dogs': 1}\n",
    "\n",
    "        # sort the class labels by index according to batches.class_indices and update model.classes\n",
    "        for c in batches.class_indices:\n",
    "            classes[batches.class_indices[c]] = c\n",
    "        self.classes = classes\n",
    "        \n",
    "            \n",
    "    def compile(self,lr=0.01):\n",
    "        \"\"\"\n",
    "            用于配置训练模型。\n",
    "            Configures the model for training.\n",
    "            See Keras documentation: https://keras.io/models/model/\n",
    "        \"\"\"\n",
    "        self.model.compile(optimizer=Adam(lr=lr),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit_data(self,X,y,val,val_lables,batch_size=64,n_epochs=3):\n",
    "        \"\"\"\n",
    "            # 训练模型\n",
    "            See Keras documentation: https://keras.io/models/model/\n",
    "        \"\"\"\n",
    "        self.model.fit(X,y,validation_data=(val,val_labels),epochs=n_epochs,batch_size=batch_size)\n",
    "    \n",
    "    \n",
    "    def fit(self,batches,val_batches,n_epochs=3,batch_size=16):\n",
    "        \"\"\"\n",
    "            使用 Python 生成器逐批生成的数据，按批次训练模型。\n",
    "            Fits the model on data yielded batch-by-batch by a Python generator.\n",
    "            See Keras documentation: https://keras.io/models/model/\n",
    "        \"\"\"\n",
    "        self.model.fit_generator(batches,steps_per_epoch =val_batches.n//batch_size,\n",
    "                                 validation_data=val_batches,epochs=n_epochs,verbose=1)\n",
    "        \n",
    "        \n",
    "    def test(self,path,batch_size=8):\n",
    "        \"\"\"\n",
    "            测试\n",
    "            Predicts the classes using the trained model on data yielded batch-by-batch.\n",
    "\n",
    "            Args:\n",
    "                path (string):  Path to the target directory. It should contain one subdirectory \n",
    "                                per class.\n",
    "                batch_size (int): The number of images to be considered in each batch.\n",
    "            \n",
    "            Returns:\n",
    "                test_batches, numpy array(s) of predictions for the test_batches.\n",
    "    \n",
    "        \"\"\"\n",
    "        test_batches = self.get_batches(path,shuffle=False,batch_size=batch_size,class_mode=None)\n",
    "        return test_batches,self.model.predict_generator(test_batches,steps = test_batches.n//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计划\n",
    "1. Create Validation and Sample sets\n",
    "2. Rearrange image files into their respective directories \n",
    "3. Finetune and Train model\n",
    "4. Generate predictions\n",
    "5. Validate predictions\n",
    "6. Submit predictions to Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 建立验证集和样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T01:02:42.235474Z",
     "start_time": "2018-07-04T01:02:42.223470Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_HOME_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T12:44:51.911688Z",
     "start_time": "2018-06-27T12:44:51.855677Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create directories 如果是linux系统\n",
    "%mkdir DATA_HOME_DIR\n",
    "%cd $DATA_HOME_DIR\n",
    "%mkdir valid\n",
    "%mkdir results\n",
    "%mkdir sample/train\n",
    "%mkdir sample/test\n",
    "%mkdir sample/valid\n",
    "%mkdir sample/results\n",
    "%mkdir test/unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T14:35:16.020175Z",
     "start_time": "2018-06-27T14:35:15.843222Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create directories 如果是Windows10 系统\n",
    "%mkdir $DATA_HOME_DIR\n",
    "%cd $DATA_HOME_DIR\n",
    "%mkdir valid\n",
    "%mkdir results\n",
    "%mkdir sample\\\\train\n",
    "%mkdir sample\\\\test\n",
    "%mkdir sample\\\\valid\n",
    "%mkdir sample\\\\results\n",
    "%mkdir test\\\\unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T01:02:12.387852Z",
     "start_time": "2018-06-28T01:02:12.383854Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_HOME_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T01:02:18.597304Z",
     "start_time": "2018-06-28T01:02:18.589310Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd $DATA_HOME_DIR\\train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linux系统\n",
    "# %cd $DATA_HOME_DIR/train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-03T14:48:08.284123Z",
     "start_time": "2018-07-03T14:48:08.256566Z"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T13:51:43.979545Z",
     "start_time": "2018-06-27T13:51:43.043830Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "g = glob('*.jpg',recursive=True)\n",
    "#print(g)\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(2000): \n",
    "    os.rename(shuf[i], DATA_HOME_DIR+'\\\\valid\\\\' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T13:51:47.151417Z",
     "start_time": "2018-06-27T13:51:47.146420Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T13:52:39.269327Z",
     "start_time": "2018-06-27T13:52:37.834788Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(200): \n",
    "    copyfile(shuf[i], DATA_HOME_DIR+'\\\\sample\\\\train\\\\' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T13:52:47.185860Z",
     "start_time": "2018-06-27T13:52:47.175868Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%cd $DATA_HOME_DIR\\valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T13:53:03.097327Z",
     "start_time": "2018-06-27T13:53:02.726407Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(50): \n",
    "    copyfile(shuf[i], DATA_HOME_DIR+'\\\\sample\\\\valid\\\\' + shuf[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 重新组织图片到相应文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T14:15:36.554169Z",
     "start_time": "2018-06-27T14:15:36.490186Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd $DATA_HOME_DIR\\sample\\train\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%dir\n",
    "%move cat.*.jpg cats\n",
    "%move dog.*.jpg dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T14:17:34.895688Z",
     "start_time": "2018-06-27T14:17:34.705745Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Divide cat/dog images into separate directories\n",
    "\n",
    "%cd $DATA_HOME_DIR\\sample\\train\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "# %move cat.*.jpg cats\n",
    "# %move dog.*.jpg dogs\n",
    "\n",
    "%cd $DATA_HOME_DIR\\sample\\valid\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "# %move cat.*.jpg cats/\n",
    "# %move dog.*.jpg dogs/\n",
    "\n",
    "%cd $DATA_HOME_DIR\\valid\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "# %move cat.*.jpg cats/\n",
    "# %move dog.*.jpg dogs/\n",
    "\n",
    "%cd $DATA_HOME_DIR\\train\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "# %move cat.*.jpg cats/\n",
    "# %move dog.*.jpg dogs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-27T14:30:15.400927Z",
     "start_time": "2018-06-27T14:30:15.389908Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create single 'unknown' class for test set\n",
    "%cd $DATA_HOME_DIR\\test\n",
    "%move *.jpg unknown\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 微调模型&训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T01:02:46.228195Z",
     "start_time": "2018-07-04T01:02:46.223198Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_HOME_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T01:02:47.361888Z",
     "start_time": "2018-07-04T01:02:47.347888Z"
    }
   },
   "outputs": [],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "\n",
    "#Set path to sample/ path if desired\n",
    "path = DATA_HOME_DIR + '\\\\' #'/sample/'\n",
    "test_path = DATA_HOME_DIR + '\\\\test\\\\' #We use all the test data\n",
    "results_path=DATA_HOME_DIR + '\\\\results\\\\'\n",
    "train_path=path + '\\\\train\\\\'\n",
    "valid_path=path + '\\\\valid\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T01:02:53.779861Z",
     "start_time": "2018-07-04T01:02:49.014362Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#import Vgg16 helper class\n",
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T01:02:55.338473Z",
     "start_time": "2018-07-04T01:02:55.311482Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T01:13:03.796768Z",
     "start_time": "2018-07-04T01:13:03.793774Z"
    }
   },
   "outputs": [],
   "source": [
    "#Set constants. You can experiment with no_of_epochs to improve the model\n",
    "batch_size=16\n",
    "no_of_epochs=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T01:03:09.254231Z",
     "start_time": "2018-07-04T01:03:06.996923Z"
    }
   },
   "outputs": [],
   "source": [
    "batches = vgg.get_batches(train_path, batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(valid_path, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T01:13:06.814807Z",
     "start_time": "2018-07-04T01:13:06.748836Z"
    }
   },
   "outputs": [],
   "source": [
    "#Finetune the model\n",
    "vgg.finetune(batches)\n",
    "\n",
    "#Not sure if we set this for all fits\n",
    "vgg.model.optimizer.lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T01:13:09.312025Z",
     "start_time": "2018-07-04T01:13:08.597241Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Notice we are passing in the validation dataset to the fit() method\n",
    "#For each epoch we test our model against the validation set\n",
    "latest_weights_filename = None\n",
    "for epoch in range(no_of_epochs):\n",
    "    print(\"Running epoch: %d\" % epoch)\n",
    "    vgg.fit(batches, val_batches,n_epochs=1,batch_size=batch_size) # 按批次训练模型\n",
    "    latest_weights_filename = 'ft%d.h5' % epoch\n",
    "    vgg.model.save_weights(results_path+latest_weights_filename)\n",
    "print(\"Completed %s fit operations\" % no_of_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 生成预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用刚刚训练的模型在测试集上做测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T01:09:07.112266Z",
     "start_time": "2018-07-04T01:09:07.098275Z"
    }
   },
   "outputs": [],
   "source": [
    "test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T01:10:40.813975Z",
     "start_time": "2018-07-04T01:09:10.736122Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batches, preds = vgg.test(test_path, batch_size = batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T01:12:13.155748Z",
     "start_time": "2018-07-04T01:12:13.140753Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#For every image, vgg.test() generates two probabilities \n",
    "#based on how we've ordered the cats/dogs directories.\n",
    "#It looks like column one is cats and column two is dogs\n",
    "print(preds[:5])\n",
    "\n",
    "filenames = batches.filenames\n",
    "print(filenames[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T01:12:15.969844Z",
     "start_time": "2018-07-04T01:12:15.820892Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 核实一下，PIL库可以展示图像\n",
    "from PIL import Image\n",
    "Image.open(test_path + filenames[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:17:06.834125Z",
     "start_time": "2018-06-28T13:17:06.827126Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:17:10.062617Z",
     "start_time": "2018-06-28T13:17:09.942586Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 保存测试结果数组，我们后面会再次用到\n",
    "save_array(results_path + 'test_preds.dat', preds)\n",
    "save_array(results_path + 'filenames.dat', filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 验证预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras' *fit()* function conveniently shows us the value of the loss function, and the accuracy, after every epoch (\"*epoch*\" refers to one full run through all training examples). The most important metrics for us to look at are for the validation set, since we want to check for over-fitting. \n",
    "\n",
    "- **Tip**: with our first model we should try to overfit before we start worrying about how to reduce over-fitting - there's no point even thinking about regularization, data augmentation, etc if you're still under-fitting! (We'll be looking at these techniques shortly).\n",
    "\n",
    "As well as looking at the overall metrics, it's also a good idea to look at examples of each of:\n",
    "1. A few correct labels at random\n",
    "2. A few incorrect labels at random\n",
    "3. The most correct labels of each class (ie those with highest probability that are correct)\n",
    "4. The most incorrect labels of each class (ie those with highest probability that are incorrect)\n",
    "5. The most uncertain labels (ie those with probability closest to 0.5)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we can learn from these examples. (In general, this is a particularly useful technique for debugging problems in the model. However, since this model is so simple, there may not be too much to learn at this stage.)\n",
    "\n",
    "Calculate predictions on validation set, so we can find correct and incorrect examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:24:22.218024Z",
     "start_time": "2018-06-28T13:24:21.532276Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取我们在之前训练保存的最后一次权重\n",
    "vgg.model.load_weights(results_path+latest_weights_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:24:55.455737Z",
     "start_time": "2018-06-28T13:24:39.962967Z"
    }
   },
   "outputs": [],
   "source": [
    "# 在验证集上测试\n",
    "val_batches, probs = vgg.test(valid_path, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:28:22.405419Z",
     "start_time": "2018-06-28T13:28:22.391451Z"
    }
   },
   "outputs": [],
   "source": [
    "filenames = val_batches.filenames # 返回验证集上的所有文件名\n",
    "expected_labels = val_batches.classes #0 or 1  真实标记\n",
    "\n",
    "#Round our predictions to 0/1 to generate labels\n",
    "our_predictions = probs[:,0]\n",
    "our_labels = np.round(1-our_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:29:23.796186Z",
     "start_time": "2018-06-28T13:29:23.785190Z"
    }
   },
   "outputs": [],
   "source": [
    "expected_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:29:51.710164Z",
     "start_time": "2018-06-28T13:29:51.691192Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "#Helper function to plot images by index in the validation set \n",
    "#Plots is a helper function in utils.py\n",
    "def plots_idx(idx, titles=None):\n",
    "    plots([image.load_img(valid_path + filenames[i]) for i in idx], titles=titles)\n",
    "    \n",
    "#Number of images to view for each visualization task\n",
    "n_view = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:31:09.528928Z",
     "start_time": "2018-06-28T13:31:09.304000Z"
    }
   },
   "outputs": [],
   "source": [
    "#1.  随机选择一些分类正确的\n",
    "correct = np.where(our_labels==expected_labels)[0]\n",
    "print(\"Found %d correct labels\" % len(correct))\n",
    "idx = permutation(correct)[:n_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:31:31.867119Z",
     "start_time": "2018-06-28T13:31:31.594221Z"
    }
   },
   "outputs": [],
   "source": [
    "#2. 不正确的\n",
    "incorrect = np.where(our_labels!=expected_labels)[0]\n",
    "print(\"Found %d incorrect labels\" % len(incorrect))\n",
    "idx = permutation(incorrect)[:n_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:32:27.031550Z",
     "start_time": "2018-06-28T13:32:26.680673Z"
    }
   },
   "outputs": [],
   "source": [
    "#3a. The images we most confident were cats, and are actually cats\n",
    "correct_cats = np.where((our_labels==0) & (our_labels==expected_labels))[0]\n",
    "print(\"Found %d confident correct cats labels\" % len(correct_cats))\n",
    "most_correct_cats = np.argsort(our_predictions[correct_cats])[::-1][:n_view]\n",
    "plots_idx(correct_cats[most_correct_cats], our_predictions[correct_cats][most_correct_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:32:50.747914Z",
     "start_time": "2018-06-28T13:32:50.464990Z"
    }
   },
   "outputs": [],
   "source": [
    "#3b. The images we most confident were dogs, and are actually dogs\n",
    "correct_dogs = np.where((our_labels==1) & (our_labels==expected_labels))[0]\n",
    "print(\"Found %d confident correct dogs labels\" % len(correct_dogs))\n",
    "most_correct_dogs = np.argsort(our_predictions[correct_dogs])[:n_view]\n",
    "plots_idx(correct_dogs[most_correct_dogs], our_predictions[correct_dogs][most_correct_dogs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:33:05.637920Z",
     "start_time": "2018-06-28T13:33:05.376978Z"
    }
   },
   "outputs": [],
   "source": [
    "#4a. The images we were most confident were cats, but are actually dogs\n",
    "incorrect_cats = np.where((our_labels==0) & (our_labels!=expected_labels))[0]\n",
    "print(\"Found %d incorrect cats\" % len(incorrect_cats))\n",
    "if len(incorrect_cats):\n",
    "    most_incorrect_cats = np.argsort(our_predictions[incorrect_cats])[::-1][:n_view]\n",
    "    plots_idx(incorrect_cats[most_incorrect_cats], our_predictions[incorrect_cats][most_incorrect_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:33:28.356702Z",
     "start_time": "2018-06-28T13:33:28.083820Z"
    }
   },
   "outputs": [],
   "source": [
    "#4b. The images we were most confident were dogs, but are actually cats\n",
    "incorrect_dogs = np.where((our_labels==1) & (our_labels!=expected_labels))[0]\n",
    "print(\"Found %d incorrect dogs\" % len(incorrect_dogs))\n",
    "if len(incorrect_dogs):\n",
    "    most_incorrect_dogs = np.argsort(our_predictions[incorrect_dogs])[:n_view]\n",
    "    plots_idx(incorrect_dogs[most_incorrect_dogs], our_predictions[incorrect_dogs][most_incorrect_dogs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:33:41.144235Z",
     "start_time": "2018-06-28T13:33:40.870357Z"
    }
   },
   "outputs": [],
   "source": [
    "#5. The most uncertain labels (ie those with probability closest to 0.5).\n",
    "most_uncertain = np.argsort(np.abs(our_predictions-0.5))\n",
    "plots_idx(most_uncertain[:n_view], our_predictions[most_uncertain])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps the most common way to analyze the result of a classification model is to use a [confusion matrix](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/). Scikit-learn has a convenient function we can use for this purpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:33:55.864130Z",
     "start_time": "2018-06-28T13:33:55.830113Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(expected_labels, our_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can just print out the confusion matrix, or we can show a graphical view (which is mainly useful for dependents with a larger number of categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:34:22.820102Z",
     "start_time": "2018-06-28T13:34:22.645173Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, val_batches.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提交结果到Kaggle！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the format Kaggle requires for new submissions:\n",
    "```\n",
    "imageId,isDog\n",
    "1242, .3984\n",
    "3947, .1000\n",
    "4539, .9082\n",
    "2345, .0000\n",
    "```\n",
    "\n",
    "Kaggle wants the imageId followed by the probability of the image being a dog. Kaggle uses a metric called [Log Loss](http://wiki.fast.ai/index.php/Log_Loss) to evaluate your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:39:45.329441Z",
     "start_time": "2018-06-28T13:39:45.266433Z"
    }
   },
   "outputs": [],
   "source": [
    "#Load our test predictions from file\n",
    "preds = load_array(results_path + 'test_preds.dat')\n",
    "filenames = load_array(results_path + 'filenames.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:40:22.581496Z",
     "start_time": "2018-06-28T13:40:22.560509Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Grab the dog prediction column\n",
    "isdog = preds[:,1]\n",
    "print(\"Raw Predictions: \" + str(isdog[:5]))\n",
    "print(\"Mid Predictions: \" + str(isdog[(isdog < .6) & (isdog > .4)]))\n",
    "print(\"Edge Predictions: \" + str(isdog[(isdog == 1) | (isdog == 0)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Log Loss](http://wiki.fast.ai/index.php/Log_Loss) doesn't support probability values of 0 or 1--they are undefined (and we have many). Fortunately, Kaggle helps us by offsetting our 0s and 1s by a very small value. So if we upload our submission now we will have lots of .99999999 and .000000001 values. This seems good, right?\n",
    "\n",
    "Not so. There is an additional twist due to how log loss is calculated--log loss rewards predictions that are confident and correct (p=.9999,label=1), but it punishes predictions that are confident and wrong far more (p=.0001,label=1). See visualization below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:45:29.354514Z",
     "start_time": "2018-06-28T13:45:29.340529Z"
    }
   },
   "outputs": [],
   "source": [
    "#Visualize Log Loss when True value = 1\n",
    "#y-axis is log loss, x-axis is probabilty that label = 1\n",
    "#As you can see Log Loss increases rapidly as we approach 0\n",
    "#But increases slowly as our predicted probability gets closer to 1\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "x = [i*.0001 for i in range(1,10000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:48:01.520847Z",
     "start_time": "2018-06-28T13:48:01.469876Z"
    }
   },
   "outputs": [],
   "source": [
    "y = [log_loss([1],[[i*.0001,1-(i*.0001)]],eps=1e-15)  for i in range(1,10000,1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y)\n",
    "plt.axis([-.05, 1.1, -.8, 10])\n",
    "plt.title(\"Log Loss when true label = 1\")\n",
    "plt.xlabel(\"predicted probability\")\n",
    "plt.ylabel(\"log loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:48:21.595818Z",
     "start_time": "2018-06-28T13:48:21.587822Z"
    }
   },
   "outputs": [],
   "source": [
    "#So to play it safe, we use a sneaky trick to round down our edge predictions\n",
    "#Swap all ones with .95 and all zeros with .05\n",
    "isdog = isdog.clip(min=0.05, max=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:48:30.674896Z",
     "start_time": "2018-06-28T13:48:30.635901Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Extract imageIds from the filenames in our test/unknown directory \n",
    "filenames = batches.filenames\n",
    "ids = np.array([int(f[8:f.find('.')]) for f in filenames])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we join the two columns into an array of [imageId, isDog]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:48:39.952548Z",
     "start_time": "2018-06-28T13:48:39.936555Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "subm = np.stack([ids,isdog], axis=1)\n",
    "subm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:48:43.854970Z",
     "start_time": "2018-06-28T13:48:43.764008Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%cd $DATA_HOME_DIR\n",
    "submission_file_name = 'submission1.csv'\n",
    "np.savetxt(submission_file_name, subm, fmt='%d,%.5f', header='id,label', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T13:48:50.276200Z",
     "start_time": "2018-06-28T13:48:50.242188Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "%cd $LESSON_HOME_DIR\n",
    "FileLink('data/redux/'+submission_file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download this file and submit on the Kaggle website or use the Kaggle command line tool's \"submit\" method."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "nav_menu": {},
  "nbpresent": {
   "slides": {
    "28b43202-5690-4169-9aca-6b9dabfeb3ec": {
     "id": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "prev": null,
     "regions": {
      "3bba644a-cf4d-4a49-9fbd-e2554428cf9f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f3d3a388-7e2a-4151-9b50-c20498fceacc",
        "part": "whole"
       },
       "id": "3bba644a-cf4d-4a49-9fbd-e2554428cf9f"
      }
     }
    },
    "8104def2-4b68-44a0-8f1b-b03bf3b2a079": {
     "id": "8104def2-4b68-44a0-8f1b-b03bf3b2a079",
     "prev": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "regions": {
      "7dded777-1ddf-4100-99ae-25cf1c15b575": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fe47bd48-3414-4657-92e7-8b8d6cb0df00",
        "part": "whole"
       },
       "id": "7dded777-1ddf-4100-99ae-25cf1c15b575"
      }
     }
    }
   },
   "themes": {}
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "148px",
    "width": "254px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "579px",
    "left": "23px",
    "top": "111px",
    "width": "207px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
