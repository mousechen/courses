{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Enter State Farm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T15:57:44.974999Z",
     "start_time": "2018-07-27T15:57:44.964004Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T03:06:54.315737Z",
     "start_time": "2018-07-28T03:06:50.566951Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "path = \"data/state/\"\n",
    "#path = \"data/state/sample/\"\n",
    "import imp\n",
    "import utils\n",
    "from utils import *\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T03:06:54.319737Z",
     "start_time": "2018-07-28T03:06:54.316738Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size= 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Setup batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T03:07:08.495279Z",
     "start_time": "2018-07-28T03:07:02.142282Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20924 images belonging to 10 classes.\n",
      "Found 1500 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(path+'train', batch_size=batch_size)\n",
    "val_batches = get_batches(path+'valid', batch_size=batch_size*2, shuffle=False)\n",
    "test_batches = get_batches(path+\"test\",batch_size=batch_size*2,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T03:07:14.293397Z",
     "start_time": "2018-07-28T03:07:08.502243Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20924 images belonging to 10 classes.\n",
      "Found 1500 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Rather than using batches, we could just import all the data into an array to save some processing time. (In most examples I'm using the batches, however - just because that's how I happened to start out.)\n",
    "\n",
    "与其使用批处理，不如将所有数据导入到数组中，以节省一些处理时间。(不过，在大多数例子中，我使用批次——只是因为我恰好就是这样开始的。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T16:02:03.539051Z",
     "start_time": "2018-07-27T15:57:53.617640Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20924 images belonging to 10 classes.\n",
      "Found 1500 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "trn = get_data(path+'train')\n",
    "val = get_data(path+'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T16:02:31.518489Z",
     "start_time": "2018-07-27T16:02:03.547049Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/val.dat', val)\n",
    "save_array(path+'results/trn.dat', trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T16:03:32.881295Z",
     "start_time": "2018-07-27T16:02:31.528486Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "val = load_array(path+'results/val.dat')\n",
    "trn = load_array(path+'results/trn.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run sample experiments on full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should find that everything that worked on the sample (see statefarm-sample.ipynb), works on the full dataset too. Only better! Because now we have more data. So let's see how they go - the models in this section are exact copies of the sample notebook models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 单个卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T00:18:05.617489Z",
     "start_time": "2018-07-28T00:18:05.587501Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def conv1(batches):\n",
    "    model = Sequential([\n",
    "            BatchNormalization(axis=1, input_shape=(3,224,224)),\n",
    "            Conv2D(filters=32,kernel_size=(3,3), activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Conv2D(filters=64,kernel_size=(3,3), activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Flatten(),\n",
    "            Dense(200, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    #model.fit_generator(batches, epochs=2, validation_data=val_batches)\n",
    "    model.fit_generator(batches, steps_per_epoch=batches.n // batch_size, epochs=2, validation_data=val_batches, \n",
    "                    validation_steps=val_batches.n // batch_size)\n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(batches, steps_per_epoch=batches.n // batch_size, epochs=4, validation_data=val_batches, \n",
    "                    validation_steps=val_batches.n // batch_size)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T16:03:33.426120Z",
     "start_time": "2018-07-27T16:03:33.234182Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches.n //batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T16:03:33.442114Z",
     "start_time": "2018-07-27T16:03:33.433117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T16:03:33.451111Z",
     "start_time": "2018-07-27T16:03:33.446113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20924"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T00:29:11.464673Z",
     "start_time": "2018-07-28T00:18:10.087158Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "326/326 [==============================] - 112s 342ms/step - loss: 0.2363 - acc: 0.9407 - val_loss: 0.0415 - val_acc: 0.9942\n",
      "Epoch 2/2\n",
      "326/326 [==============================] - 110s 339ms/step - loss: 0.0149 - acc: 0.9987 - val_loss: 0.0197 - val_acc: 0.9955\n",
      "Epoch 1/4\n",
      "326/326 [==============================] - 110s 338ms/step - loss: 0.0045 - acc: 0.9998 - val_loss: 0.0145 - val_acc: 0.9972\n",
      "Epoch 2/4\n",
      "326/326 [==============================] - 108s 332ms/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0101 - val_acc: 0.9969\n",
      "Epoch 3/4\n",
      "326/326 [==============================] - 110s 336ms/step - loss: 0.0023 - acc: 0.9999 - val_loss: 0.0086 - val_acc: 0.9976\n",
      "Epoch 4/4\n",
      "326/326 [==============================] - 108s 331ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 0.9972\n"
     ]
    }
   ],
   "source": [
    "model = conv1(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T00:32:14.287805Z",
     "start_time": "2018-07-28T00:32:14.045862Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_weights(path+'models/single_conv.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T00:34:05.983172Z",
     "start_time": "2018-07-28T00:34:05.978178Z"
    }
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T00:38:03.896834Z",
     "start_time": "2018-07-28T00:34:07.892667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "326/326 [==============================] - 125s 383ms/step - loss: 8.3423e-04 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 0.9972\n",
      "Epoch 2/2\n",
      "326/326 [==============================] - 111s 340ms/step - loss: 6.8582e-04 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 0.9979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17874fdec18>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, steps_per_epoch=batches.n // batch_size, epochs=2, validation_data=val_batches, \n",
    "                    validation_steps=val_batches.n // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T00:50:39.468802Z",
     "start_time": "2018-07-28T00:41:26.627935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "326/326 [==============================] - 110s 338ms/step - loss: 5.1904e-04 - acc: 1.0000 - val_loss: 0.0056 - val_acc: 0.9979\n",
      "Epoch 2/5\n",
      "326/326 [==============================] - 110s 338ms/step - loss: 4.4860e-04 - acc: 1.0000 - val_loss: 0.0053 - val_acc: 0.9979\n",
      "Epoch 3/5\n",
      "326/326 [==============================] - 111s 340ms/step - loss: 3.6310e-04 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 0.9979\n",
      "Epoch 4/5\n",
      "326/326 [==============================] - 112s 342ms/step - loss: 3.0750e-04 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 0.9986\n",
      "Epoch 5/5\n",
      "326/326 [==============================] - 110s 337ms/step - loss: 2.6324e-04 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 0.9979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17640370c50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, steps_per_epoch=batches.n // batch_size, epochs=5, validation_data=val_batches, \n",
    "                    validation_steps=val_batches.n // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Interestingly, with no regularization or augmentation we're getting some reasonable results from our simple convolutional model. So with augmentation, we hopefully will see some very good results.\n",
    "\n",
    "有趣的是，由于没有正规化或增强，我们从简单的卷积模型得到了一些合理的结果。因此，通过增加，我们希望能看到一些很好的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 数据增广"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T01:10:34.352769Z",
     "start_time": "2018-07-28T01:10:31.799505Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20924 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "batches = get_batches(path+'train', gen_t, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T15:57:01.145553Z",
     "start_time": "2018-07-27T15:27:23.935746Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = conv1(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-21T15:27:47.842650Z",
     "start_time": "2018-07-21T15:27:47.828662Z"
    }
   },
   "outputs": [],
   "source": [
    "1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T00:42:30.900763Z",
     "start_time": "2018-07-26T23:25:19.375293Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 在之前的模型上，变更学习率为0.00001\n",
    "model.optimizer.lr = 0.0001\n",
    "# model.fit_generator(batches, steps_per_epoch=batches.n // batch_size, epochs=15, validation_data=val_batches, \n",
    "#                     validation_steps=val_batches.n // batch_size)\n",
    "model.fit_generator(batches, epochs=15, validation_data=val_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I'm shocked by *how* good these results are! We're regularly seeing 75-80% accuracy on the validation set, which puts us into the top third or better of the competition. With such a simple model and no dropout or semi-supervised learning, this really speaks to the power of this approach to data augmentation.\n",
    "\n",
    "我对这些结果如此之好感到震惊!我们经常在验证集上看到75-80%的准确率，这使我们进入了竞争中排名前三或更高的位置。有了这样一个简单的模型，没有dropout或半监督学习，这就证明了这种方法对数据增强的作用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Four conv/pooling pairs + dropout "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Unfortunately, the results are still very unstable - the validation accuracy jumps from epoch to epoch. Perhaps a deeper model with some dropout would help.\n",
    "\n",
    "由于显卡太烂，这个部分无法训练完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T16:01:48.379677Z",
     "start_time": "2018-07-28T16:01:47.292980Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20924 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "batches = get_batches(path+'train', gen_t, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T03:07:19.127870Z",
     "start_time": "2018-07-28T03:07:16.639630Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "        BatchNormalization(axis=1, input_shape=(3,224,224)),\n",
    "        Conv2D(32,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(64,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(128,3, activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(200, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(200, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T03:07:19.134829Z",
     "start_time": "2018-07-28T03:07:19.128845Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_1 (Batch (None, 3, 224, 224)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 222, 222)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 222, 222)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 111, 111)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 109, 109)      18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64, 109, 109)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 64, 54, 54)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 128, 52, 52)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128, 52, 52)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 128, 26, 26)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 86528)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               17305800  \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 17,443,766\n",
      "Trainable params: 17,442,512\n",
      "Non-trainable params: 1,254\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T01:10:59.447687Z",
     "start_time": "2018-07-28T01:10:59.434697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0001"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T01:11:01.186087Z",
     "start_time": "2018-07-28T01:11:01.175112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T03:07:47.273010Z",
     "start_time": "2018-07-28T03:07:47.238011Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=10e-5), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T03:19:35.063730Z",
     "start_time": "2018-07-28T03:07:52.631340Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "326/326 [==============================] - 356s 1s/step - loss: 2.4579 - acc: 0.2911 - val_loss: 0.8844 - val_acc: 0.7180\n",
      "Epoch 2/2\n",
      "326/326 [==============================] - 345s 1s/step - loss: 1.6295 - acc: 0.4888 - val_loss: 0.6182 - val_acc: 0.8119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1769018ccc0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, steps_per_epoch=batches.n // batch_size, epochs=2, validation_data=val_batches, \n",
    "                    validation_steps=val_batches.n // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T03:19:41.178779Z",
     "start_time": "2018-07-28T03:19:41.175781Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.001 # 提高学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T04:17:17.005191Z",
     "start_time": "2018-07-28T03:20:13.281464Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "326/326 [==============================] - 339s 1s/step - loss: 1.1831 - acc: 0.6165 - val_loss: 0.3087 - val_acc: 0.9175\n",
      "Epoch 2/10\n",
      "326/326 [==============================] - 341s 1s/step - loss: 0.8898 - acc: 0.7039 - val_loss: 0.2103 - val_acc: 0.9415\n",
      "Epoch 3/10\n",
      "326/326 [==============================] - 336s 1s/step - loss: 0.7145 - acc: 0.7616 - val_loss: 0.1765 - val_acc: 0.9532\n",
      "Epoch 4/10\n",
      "326/326 [==============================] - 338s 1s/step - loss: 0.5823 - acc: 0.8082 - val_loss: 0.1408 - val_acc: 0.9587\n",
      "Epoch 5/10\n",
      "326/326 [==============================] - 344s 1s/step - loss: 0.4963 - acc: 0.8383 - val_loss: 0.1385 - val_acc: 0.9580\n",
      "Epoch 6/10\n",
      "326/326 [==============================] - 346s 1s/step - loss: 0.4112 - acc: 0.8643 - val_loss: 0.1169 - val_acc: 0.9721\n",
      "Epoch 7/10\n",
      "326/326 [==============================] - 349s 1s/step - loss: 0.3640 - acc: 0.8800 - val_loss: 0.0853 - val_acc: 0.9787\n",
      "Epoch 8/10\n",
      "326/326 [==============================] - 343s 1s/step - loss: 0.3232 - acc: 0.8962 - val_loss: 0.0996 - val_acc: 0.9783\n",
      "Epoch 9/10\n",
      "326/326 [==============================] - 344s 1s/step - loss: 0.2763 - acc: 0.9110 - val_loss: 0.0736 - val_acc: 0.9821\n",
      "Epoch 10/10\n",
      "326/326 [==============================] - 343s 1s/step - loss: 0.2641 - acc: 0.9144 - val_loss: 0.0974 - val_acc: 0.9735\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(batches, steps_per_epoch=batches.n // batch_size, epochs=10, validation_data=val_batches, \n",
    "                    validation_steps=val_batches.n // batch_size)\n",
    "model.save_weights(path+'models/four_conv.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T04:25:01.766923Z",
     "start_time": "2018-07-28T04:25:01.762924Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr=0.00001 # 降低学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T05:20:33.247427Z",
     "start_time": "2018-07-28T04:25:03.471378Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "326/326 [==============================] - 335s 1s/step - loss: 0.2340 - acc: 0.9277 - val_loss: 0.0740 - val_acc: 0.9790\n",
      "Epoch 2/10\n",
      "326/326 [==============================] - 335s 1s/step - loss: 0.2105 - acc: 0.9335 - val_loss: 0.0540 - val_acc: 0.9873\n",
      "Epoch 3/10\n",
      "326/326 [==============================] - 353s 1s/step - loss: 0.2030 - acc: 0.9353 - val_loss: 0.0592 - val_acc: 0.9842\n",
      "Epoch 4/10\n",
      "326/326 [==============================] - 331s 1s/step - loss: 0.1765 - acc: 0.9452 - val_loss: 0.0604 - val_acc: 0.9831\n",
      "Epoch 5/10\n",
      "326/326 [==============================] - 329s 1s/step - loss: 0.1845 - acc: 0.9432 - val_loss: 0.0542 - val_acc: 0.9862\n",
      "Epoch 6/10\n",
      "326/326 [==============================] - 332s 1s/step - loss: 0.1606 - acc: 0.9486 - val_loss: 0.0579 - val_acc: 0.9845\n",
      "Epoch 7/10\n",
      "326/326 [==============================] - 334s 1s/step - loss: 0.1514 - acc: 0.9517 - val_loss: 0.0541 - val_acc: 0.9818\n",
      "Epoch 8/10\n",
      "326/326 [==============================] - 331s 1s/step - loss: 0.1464 - acc: 0.9538 - val_loss: 0.0634 - val_acc: 0.9838\n",
      "Epoch 9/10\n",
      "326/326 [==============================] - 325s 997ms/step - loss: 0.1347 - acc: 0.9574 - val_loss: 0.0587 - val_acc: 0.9852\n",
      "Epoch 10/10\n",
      "326/326 [==============================] - 326s 999ms/step - loss: 0.1327 - acc: 0.9588 - val_loss: 0.0407 - val_acc: 0.9921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17690183e10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, steps_per_epoch=batches.n // batch_size, epochs=10, validation_data=val_batches, \n",
    "                    validation_steps=val_batches.n // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T05:20:57.289748Z",
     "start_time": "2018-07-28T05:20:57.082842Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_weights(path+'models/four_conv.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T07:28:53.203008Z",
     "start_time": "2018-07-28T05:32:02.186556Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "326/326 [==============================] - 360s 1s/step - loss: 0.1172 - acc: 0.9637 - val_loss: 0.0518 - val_acc: 0.9897\n",
      "Epoch 2/20\n",
      "326/326 [==============================] - 362s 1s/step - loss: 0.1198 - acc: 0.9643 - val_loss: 0.0495 - val_acc: 0.9880\n",
      "Epoch 3/20\n",
      "326/326 [==============================] - 364s 1s/step - loss: 0.1101 - acc: 0.9660 - val_loss: 0.0552 - val_acc: 0.9876\n",
      "Epoch 4/20\n",
      "326/326 [==============================] - 360s 1s/step - loss: 0.1081 - acc: 0.9661 - val_loss: 0.0687 - val_acc: 0.9790\n",
      "Epoch 5/20\n",
      "326/326 [==============================] - 358s 1s/step - loss: 0.1057 - acc: 0.9676 - val_loss: 0.0682 - val_acc: 0.9811\n",
      "Epoch 6/20\n",
      "326/326 [==============================] - 356s 1s/step - loss: 0.0980 - acc: 0.9679 - val_loss: 0.0466 - val_acc: 0.9869\n",
      "Epoch 7/20\n",
      "326/326 [==============================] - 353s 1s/step - loss: 0.0979 - acc: 0.9691 - val_loss: 0.0523 - val_acc: 0.9890\n",
      "Epoch 8/20\n",
      "326/326 [==============================] - 353s 1s/step - loss: 0.0887 - acc: 0.9722 - val_loss: 0.0436 - val_acc: 0.9907\n",
      "Epoch 9/20\n",
      "326/326 [==============================] - 369s 1s/step - loss: 0.0893 - acc: 0.9723 - val_loss: 0.0603 - val_acc: 0.9838\n",
      "Epoch 10/20\n",
      "326/326 [==============================] - 346s 1s/step - loss: 0.0830 - acc: 0.9744 - val_loss: 0.0516 - val_acc: 0.9862\n",
      "Epoch 11/20\n",
      "326/326 [==============================] - 348s 1s/step - loss: 0.0777 - acc: 0.9756 - val_loss: 0.0491 - val_acc: 0.9900\n",
      "Epoch 12/20\n",
      "326/326 [==============================] - 357s 1s/step - loss: 0.0831 - acc: 0.9736 - val_loss: 0.0465 - val_acc: 0.9904\n",
      "Epoch 13/20\n",
      "326/326 [==============================] - 349s 1s/step - loss: 0.0763 - acc: 0.9752 - val_loss: 0.0351 - val_acc: 0.9914\n",
      "Epoch 14/20\n",
      "326/326 [==============================] - 347s 1s/step - loss: 0.0729 - acc: 0.9778 - val_loss: 0.0320 - val_acc: 0.9914\n",
      "Epoch 15/20\n",
      "326/326 [==============================] - 337s 1s/step - loss: 0.0686 - acc: 0.9787 - val_loss: 0.0364 - val_acc: 0.9921\n",
      "Epoch 16/20\n",
      "326/326 [==============================] - 334s 1s/step - loss: 0.0698 - acc: 0.9771 - val_loss: 0.0385 - val_acc: 0.9883\n",
      "Epoch 17/20\n",
      "326/326 [==============================] - 347s 1s/step - loss: 0.0716 - acc: 0.9783 - val_loss: 0.0361 - val_acc: 0.9924\n",
      "Epoch 18/20\n",
      "326/326 [==============================] - 343s 1s/step - loss: 0.0660 - acc: 0.9807 - val_loss: 0.0287 - val_acc: 0.9948\n",
      "Epoch 19/20\n",
      "326/326 [==============================] - 334s 1s/step - loss: 0.0639 - acc: 0.9800 - val_loss: 0.0352 - val_acc: 0.9914\n",
      "Epoch 20/20\n",
      "326/326 [==============================] - 334s 1s/step - loss: 0.0584 - acc: 0.9824 - val_loss: 0.0440 - val_acc: 0.9907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x178f17e7c50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches, steps_per_epoch=batches.n // batch_size, epochs=20, validation_data=val_batches, \n",
    "                    validation_steps=val_batches.n // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T15:56:49.954244Z",
     "start_time": "2018-07-28T15:56:49.785259Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save_weights(path+'models/four_conv_20.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is looking quite a bit better - the accuracy is similar, but the stability is higher. There's still some way to go however..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imagenet conv features 有报错暂时无法尝试这里"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have so little data, and it is similar to imagenet images (full color photos), using pre-trained VGG weights is likely to be helpful - in fact it seems likely that we won't need to fine-tune the convolutional layer weights much, if at all. So we can pre-compute the output of the last convolutional layer, as we did in lesson 3 when we experimented with dropout. (However this means that we can't use full data augmentation, since we can't pre-compute something that changes every image.)\n",
    "\n",
    "\n",
    "由于我们的数据如此之少，而且它与imagenet图像(全彩照片)相似，使用预先训练的VGG权重很可能是有用的——事实上，我们似乎不需要调整卷积层的权重，如果有的话。所以我们可以预先计算最后一个卷积层的输出，就像我们在第3课中做的那样，当我们做dropout实验的时候。(然而，这意味着我们不能使用全数据增强，因为我们不能预先计算改变每一张图像的东西。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T16:03:04.497279Z",
     "start_time": "2018-07-28T16:03:01.942099Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T16:03:07.447333Z",
     "start_time": "2018-07-28T16:03:07.444334Z"
    }
   },
   "outputs": [],
   "source": [
    "model = vgg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T16:03:08.903865Z",
     "start_time": "2018-07-28T16:03:08.896866Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 3, 224, 224)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 3, 226, 226)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 224, 224)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 64, 226, 226)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 64, 224, 224)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 64, 112, 112)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 64, 114, 114)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 128, 112, 112)     73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 128, 114, 114)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 112, 112)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 128, 56, 56)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 128, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 256, 56, 56)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 256, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 256, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 256, 28, 28)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 256, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 512, 28, 28)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 512, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 512, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 512, 14, 14)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPaddi (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 512, 7, 7)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T16:03:35.107001Z",
     "start_time": "2018-07-28T16:03:35.103002Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 <class 'keras.layers.convolutional.Conv2D'>\n",
      "4 <class 'keras.layers.convolutional.Conv2D'>\n",
      "7 <class 'keras.layers.convolutional.Conv2D'>\n",
      "9 <class 'keras.layers.convolutional.Conv2D'>\n",
      "12 <class 'keras.layers.convolutional.Conv2D'>\n",
      "14 <class 'keras.layers.convolutional.Conv2D'>\n",
      "16 <class 'keras.layers.convolutional.Conv2D'>\n",
      "19 <class 'keras.layers.convolutional.Conv2D'>\n",
      "21 <class 'keras.layers.convolutional.Conv2D'>\n",
      "23 <class 'keras.layers.convolutional.Conv2D'>\n",
      "26 <class 'keras.layers.convolutional.Conv2D'>\n",
      "28 <class 'keras.layers.convolutional.Conv2D'>\n",
      "30 <class 'keras.layers.convolutional.Conv2D'>\n"
     ]
    }
   ],
   "source": [
    "# 寻找最后一个卷积层\n",
    "\n",
    "for i,layer in enumerate(model.layers):\n",
    "    if type(layer) is Conv2D:\n",
    "        print(i,type(layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T16:03:38.128156Z",
     "start_time": "2018-07-28T16:03:38.124158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 7, 9, 12, 14, 16, 19, 21, 23, 26, 28, 30]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i,layer in enumerate(model.layers) if type(layer) is Conv2D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T16:03:39.520730Z",
     "start_time": "2018-07-28T16:03:39.517741Z"
    }
   },
   "outputs": [],
   "source": [
    "last_conv_idx = [i for i,layer in enumerate(model.layers) if type(layer) is Conv2D][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T16:03:41.086228Z",
     "start_time": "2018-07-28T16:03:41.081241Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_conv_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T16:05:23.550909Z",
     "start_time": "2018-07-28T16:05:23.547926Z"
    }
   },
   "outputs": [],
   "source": [
    "conv_layers = model.layers[:last_conv_idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T16:05:46.022795Z",
     "start_time": "2018-07-28T16:05:45.955806Z"
    }
   },
   "outputs": [],
   "source": [
    "# 建立顺序模型\n",
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T16:05:52.799690Z",
     "start_time": "2018-07-28T16:05:52.796693Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T16:05:55.194970Z",
     "start_time": "2018-07-28T16:05:54.111303Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20924 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "# batches shuffle must be set to False when pre-computing features\n",
    "# 在预训练模型中，获取批量数据不能打乱\n",
    "batches = get_batches(path+'train', batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T16:06:07.841102Z",
     "start_time": "2018-07-28T16:06:01.801034Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20924 images belonging to 10 classes.\n",
      "Found 1500 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "(val_classes, trn_classes, val_labels, trn_labels, \n",
    "    val_filenames, filenames, test_filenames) = get_classes(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T16:11:10.138279Z",
     "start_time": "2018-07-28T16:11:10.133265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1308"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T16:13:07.426128Z",
     "start_time": "2018-07-28T16:11:21.736632Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1145/1308 [=========================>....] - ETA: 13s"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Dst tensor is not initialized.\n\t [[Node: conv2d_16_1/Relu/_677 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_162_conv2d_16_1/Relu\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Dst tensor is not initialized.\n\t [[Node: conv2d_16_1/Relu/_677 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_162_conv2d_16_1/Relu\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-b295a6035204>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconv_feat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 训练\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[1;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m   1390\u001b[0m                                             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m                                             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m                                             verbose=verbose)\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[1;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m   2538\u001b[0m                     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2540\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2541\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2542\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1943\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1944\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_predict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1945\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1946\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1947\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Dst tensor is not initialized.\n\t [[Node: conv2d_16_1/Relu/_677 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_162_conv2d_16_1/Relu\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]"
     ]
    }
   ],
   "source": [
    "conv_feat = conv_model.predict_generator(batches,verbose=1) # 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T02:51:17.428124Z",
     "start_time": "2018-07-27T02:49:35.488910Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "conv_val_feat = conv_model.predict_generator(val_batches,steps=val_batches.n//batch_size) # 验证\n",
    "conv_test_feat = conv_model.predict_generator(test_batches,steps=test_batches.n //batch_size) # 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array(path+'results/conv_val_feat.dat', conv_val_feat)\n",
    "save_array(path+'results/conv_test_feat.dat', conv_test_feat)\n",
    "save_array(path+'results/conv_feat.dat', conv_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_feat = load_array(path+'results/conv_feat.dat')\n",
    "conv_val_feat = load_array(path+'results/conv_val_feat.dat')\n",
    "conv_val_feat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Batchnorm dense layers on pretrained conv layers 有问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since we've pre-computed the output of the last convolutional layer, we need to create a network that takes that as input, and predicts our 10 classes. Let's try using a simplified version of VGG's dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_bn_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p/2),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p/2),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(10, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model = Sequential(get_bn_layers(p))\n",
    "bn_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=1, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bn_model.fit(conv_feat, trn_labels, batch_size=batch_size, nb_epoch=2, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(path+'models/conv8.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Looking good! Let's try pre-computing 5 epochs worth of augmented data, so we can experiment with combining dropout and augmentation on the pre-trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Pre-computed data augmentation + dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We'll use our usual data augmentation parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T03:39:14.299136Z",
     "start_time": "2018-07-27T03:39:12.861548Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gen_t = image.ImageDataGenerator(rotation_range=15, height_shift_range=0.05, \n",
    "                shear_range=0.1, channel_shift_range=20, width_shift_range=0.1)\n",
    "da_batches = get_batches(path+'train', gen_t, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We use those to create a dataset of convolutional features 5x bigger than the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-27T03:39:19.288762Z",
     "start_time": "2018-07-27T03:39:19.069863Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "da_conv_feat = conv_model.predict_generator(da_batches, da_batches.nb_sample*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "save_array(path+'results/da_conv_feat2.dat', da_conv_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "da_conv_feat = load_array(path+'results/da_conv_feat2.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's include the real training data as well in its non-augmented form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "da_conv_feat = np.concatenate([da_conv_feat, conv_feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since we've now got a dataset 6x bigger than before, we'll need to copy our labels 6 times too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "da_trn_labels = np.concatenate([trn_labels]*6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Based on some experiments the previous model works well, with bigger dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_bn_da_layers(p):\n",
    "    return [\n",
    "        MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "        Flatten(),\n",
    "        Dropout(p),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(p),\n",
    "        Dense(10, activation='softmax')\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model = Sequential(get_bn_da_layers(p))\n",
    "bn_model.compile(Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we can train the model as usual, with pre-computed augmented data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bn_model.fit(da_conv_feat, da_trn_labels, batch_size=batch_size, nb_epoch=1, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.fit(da_conv_feat, da_trn_labels, batch_size=batch_size, nb_epoch=4, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.fit(da_conv_feat, da_trn_labels, batch_size=batch_size, nb_epoch=4, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Looks good - let's save those weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(path+'models/da_conv8_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Pseudo labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We're going to try using a combination of [pseudo labeling](http://deeplearning.net/wp-content/uploads/2013/03/pseudo_label_final.pdf) and [knowledge distillation](https://arxiv.org/abs/1503.02531) to allow us to use unlabeled data (i.e. do semi-supervised learning). For our initial experiment we'll use the validation set as the unlabeled data, so that we can see that it is working without using the test set. At a later date we'll try using the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To do this, we simply calculate the predictions of our model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "val_pseudo = bn_model.predict(conv_val_feat, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "...concatenate them with our training labels..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comb_pseudo = np.concatenate([da_trn_labels, val_pseudo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comb_feat = np.concatenate([da_conv_feat, conv_val_feat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "...and fine-tune our model using that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.load_weights(path+'models/da_conv8_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.fit(comb_feat, comb_pseudo, batch_size=batch_size, nb_epoch=1, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bn_model.fit(comb_feat, comb_pseudo, batch_size=batch_size, nb_epoch=4, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.optimizer.lr=0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bn_model.fit(comb_feat, comb_pseudo, batch_size=batch_size, nb_epoch=4, \n",
    "             validation_data=(conv_val_feat, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "That's a distinct improvement - even although the validation set isn't very big. This looks encouraging for when we try this on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bn_model.save_weights(path+'models/bn-ps8.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提交"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll find a good clipping amount using the validation set, prior to submitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T07:56:50.293143Z",
     "start_time": "2018-07-28T07:56:50.287149Z"
    }
   },
   "outputs": [],
   "source": [
    "def do_clip(arr, mx): \n",
    "    return np.clip(arr, (1-mx)/9, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T07:56:50.302142Z",
     "start_time": "2018-07-28T07:56:50.296142Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79726"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_batches.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T08:03:13.110380Z",
     "start_time": "2018-07-28T07:56:50.311139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623/623 [==============================] - 383s 614ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict_generator(test_batches,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T08:03:13.119378Z",
     "start_time": "2018-07-28T08:03:13.112381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79726, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T08:03:13.130374Z",
     "start_time": "2018-07-28T08:03:13.121377Z"
    }
   },
   "outputs": [],
   "source": [
    "subm = do_clip(preds,0.93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T08:03:13.135374Z",
     "start_time": "2018-07-28T08:03:13.133373Z"
    }
   },
   "outputs": [],
   "source": [
    "subm_name = path+'results/subm.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T08:03:13.141372Z",
     "start_time": "2018-07-28T08:03:13.138373Z"
    }
   },
   "outputs": [],
   "source": [
    "classes = sorted(batches.class_indices, key=batches.class_indices.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T08:03:13.148371Z",
     "start_time": "2018-07-28T08:03:13.144370Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T08:03:13.156365Z",
     "start_time": "2018-07-28T08:03:13.151367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79726"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T08:03:13.186356Z",
     "start_time": "2018-07-28T08:03:13.158364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['img_1.jpg',\n",
       " 'img_10.jpg',\n",
       " 'img_100.jpg',\n",
       " 'img_1000.jpg',\n",
       " 'img_100000.jpg',\n",
       " 'img_100001.jpg',\n",
       " 'img_100002.jpg',\n",
       " 'img_100003.jpg',\n",
       " 'img_100004.jpg',\n",
       " 'img_100005.jpg',\n",
       " 'img_100007.jpg',\n",
       " 'img_100008.jpg',\n",
       " 'img_100009.jpg',\n",
       " 'img_10001.jpg',\n",
       " 'img_100010.jpg',\n",
       " 'img_100011.jpg',\n",
       " 'img_100012.jpg',\n",
       " 'img_100013.jpg',\n",
       " 'img_100014.jpg',\n",
       " 'img_100016.jpg',\n",
       " 'img_100017.jpg',\n",
       " 'img_100018.jpg',\n",
       " 'img_100019.jpg',\n",
       " 'img_10002.jpg',\n",
       " 'img_100020.jpg',\n",
       " 'img_100022.jpg',\n",
       " 'img_100023.jpg',\n",
       " 'img_100024.jpg',\n",
       " 'img_100025.jpg',\n",
       " 'img_100028.jpg',\n",
       " 'img_100030.jpg',\n",
       " 'img_100031.jpg',\n",
       " 'img_100032.jpg',\n",
       " 'img_100033.jpg',\n",
       " 'img_100034.jpg',\n",
       " 'img_100035.jpg',\n",
       " 'img_100037.jpg',\n",
       " 'img_100038.jpg',\n",
       " 'img_100039.jpg',\n",
       " 'img_10004.jpg',\n",
       " 'img_100040.jpg',\n",
       " 'img_100042.jpg',\n",
       " 'img_100043.jpg',\n",
       " 'img_100044.jpg',\n",
       " 'img_100047.jpg',\n",
       " 'img_100049.jpg',\n",
       " 'img_10005.jpg',\n",
       " 'img_100051.jpg',\n",
       " 'img_100052.jpg',\n",
       " 'img_100053.jpg',\n",
       " 'img_100054.jpg',\n",
       " 'img_100055.jpg',\n",
       " 'img_100056.jpg',\n",
       " 'img_100058.jpg',\n",
       " 'img_100059.jpg',\n",
       " 'img_10006.jpg',\n",
       " 'img_100060.jpg',\n",
       " 'img_100062.jpg',\n",
       " 'img_100063.jpg',\n",
       " 'img_100064.jpg',\n",
       " 'img_100066.jpg',\n",
       " 'img_100067.jpg',\n",
       " 'img_100068.jpg',\n",
       " 'img_100069.jpg',\n",
       " 'img_10007.jpg',\n",
       " 'img_100070.jpg',\n",
       " 'img_100071.jpg',\n",
       " 'img_100072.jpg',\n",
       " 'img_100073.jpg',\n",
       " 'img_100075.jpg',\n",
       " 'img_100077.jpg',\n",
       " 'img_100078.jpg',\n",
       " 'img_100079.jpg',\n",
       " 'img_10008.jpg',\n",
       " 'img_100080.jpg',\n",
       " 'img_100081.jpg',\n",
       " 'img_100082.jpg',\n",
       " 'img_100083.jpg',\n",
       " 'img_100084.jpg',\n",
       " 'img_100085.jpg',\n",
       " 'img_100086.jpg',\n",
       " 'img_100087.jpg',\n",
       " 'img_100088.jpg',\n",
       " 'img_100089.jpg',\n",
       " 'img_10009.jpg',\n",
       " 'img_100091.jpg',\n",
       " 'img_100092.jpg',\n",
       " 'img_100093.jpg',\n",
       " 'img_100094.jpg',\n",
       " 'img_100095.jpg',\n",
       " 'img_100096.jpg',\n",
       " 'img_100097.jpg',\n",
       " 'img_100098.jpg',\n",
       " 'img_100099.jpg',\n",
       " 'img_1001.jpg',\n",
       " 'img_10010.jpg',\n",
       " 'img_100101.jpg',\n",
       " 'img_100102.jpg',\n",
       " 'img_100103.jpg',\n",
       " 'img_100104.jpg',\n",
       " 'img_100105.jpg',\n",
       " 'img_100106.jpg',\n",
       " 'img_100107.jpg',\n",
       " 'img_100110.jpg',\n",
       " 'img_100111.jpg',\n",
       " 'img_100112.jpg',\n",
       " 'img_100114.jpg',\n",
       " 'img_100115.jpg',\n",
       " 'img_100117.jpg',\n",
       " 'img_100118.jpg',\n",
       " 'img_100119.jpg',\n",
       " 'img_100120.jpg',\n",
       " 'img_100122.jpg',\n",
       " 'img_100123.jpg',\n",
       " 'img_100124.jpg',\n",
       " 'img_100125.jpg',\n",
       " 'img_100127.jpg',\n",
       " 'img_100128.jpg',\n",
       " 'img_100129.jpg',\n",
       " 'img_10013.jpg',\n",
       " 'img_100130.jpg',\n",
       " 'img_100131.jpg',\n",
       " 'img_100132.jpg',\n",
       " 'img_100133.jpg',\n",
       " 'img_100134.jpg',\n",
       " 'img_100137.jpg',\n",
       " 'img_100138.jpg',\n",
       " 'img_10014.jpg',\n",
       " 'img_100140.jpg',\n",
       " 'img_100141.jpg',\n",
       " 'img_100142.jpg',\n",
       " 'img_100143.jpg',\n",
       " 'img_100146.jpg',\n",
       " 'img_100147.jpg',\n",
       " 'img_100148.jpg',\n",
       " 'img_100149.jpg',\n",
       " 'img_10015.jpg',\n",
       " 'img_100150.jpg',\n",
       " 'img_100151.jpg',\n",
       " 'img_100154.jpg',\n",
       " 'img_100156.jpg',\n",
       " 'img_100157.jpg',\n",
       " 'img_100158.jpg',\n",
       " 'img_100159.jpg',\n",
       " 'img_10016.jpg',\n",
       " 'img_100160.jpg',\n",
       " 'img_100161.jpg',\n",
       " 'img_100162.jpg',\n",
       " 'img_100163.jpg',\n",
       " 'img_100165.jpg',\n",
       " 'img_100166.jpg',\n",
       " 'img_100169.jpg',\n",
       " 'img_10017.jpg',\n",
       " 'img_100170.jpg',\n",
       " 'img_100171.jpg',\n",
       " 'img_100172.jpg',\n",
       " 'img_100173.jpg',\n",
       " 'img_100174.jpg',\n",
       " 'img_100175.jpg',\n",
       " 'img_100177.jpg',\n",
       " 'img_100178.jpg',\n",
       " 'img_100179.jpg',\n",
       " 'img_10018.jpg',\n",
       " 'img_100180.jpg',\n",
       " 'img_100182.jpg',\n",
       " 'img_100183.jpg',\n",
       " 'img_100184.jpg',\n",
       " 'img_100185.jpg',\n",
       " 'img_100186.jpg',\n",
       " 'img_100187.jpg',\n",
       " 'img_100189.jpg',\n",
       " 'img_10019.jpg',\n",
       " 'img_100192.jpg',\n",
       " 'img_100193.jpg',\n",
       " 'img_100194.jpg',\n",
       " 'img_100195.jpg',\n",
       " 'img_100196.jpg',\n",
       " 'img_100197.jpg',\n",
       " 'img_100198.jpg',\n",
       " 'img_100199.jpg',\n",
       " 'img_1002.jpg',\n",
       " 'img_10020.jpg',\n",
       " 'img_100202.jpg',\n",
       " 'img_100203.jpg',\n",
       " 'img_100204.jpg',\n",
       " 'img_100205.jpg',\n",
       " 'img_100206.jpg',\n",
       " 'img_100207.jpg',\n",
       " 'img_100208.jpg',\n",
       " 'img_100209.jpg',\n",
       " 'img_10021.jpg',\n",
       " 'img_100210.jpg',\n",
       " 'img_100211.jpg',\n",
       " 'img_100212.jpg',\n",
       " 'img_100213.jpg',\n",
       " 'img_100214.jpg',\n",
       " 'img_100216.jpg',\n",
       " 'img_100217.jpg',\n",
       " 'img_100218.jpg',\n",
       " 'img_100219.jpg',\n",
       " 'img_10022.jpg',\n",
       " 'img_100220.jpg',\n",
       " 'img_100221.jpg',\n",
       " 'img_100222.jpg',\n",
       " 'img_100223.jpg',\n",
       " 'img_100224.jpg',\n",
       " 'img_100226.jpg',\n",
       " 'img_100227.jpg',\n",
       " 'img_100228.jpg',\n",
       " 'img_100229.jpg',\n",
       " 'img_10023.jpg',\n",
       " 'img_100231.jpg',\n",
       " 'img_100233.jpg',\n",
       " 'img_100234.jpg',\n",
       " 'img_100236.jpg',\n",
       " 'img_100237.jpg',\n",
       " 'img_100238.jpg',\n",
       " 'img_100239.jpg',\n",
       " 'img_10024.jpg',\n",
       " 'img_100240.jpg',\n",
       " 'img_100243.jpg',\n",
       " 'img_100244.jpg',\n",
       " 'img_100245.jpg',\n",
       " 'img_100247.jpg',\n",
       " 'img_100248.jpg',\n",
       " 'img_100249.jpg',\n",
       " 'img_100250.jpg',\n",
       " 'img_100252.jpg',\n",
       " 'img_100253.jpg',\n",
       " 'img_100254.jpg',\n",
       " 'img_100255.jpg',\n",
       " 'img_100258.jpg',\n",
       " 'img_100259.jpg',\n",
       " 'img_10026.jpg',\n",
       " 'img_100260.jpg',\n",
       " 'img_100261.jpg',\n",
       " 'img_100262.jpg',\n",
       " 'img_100263.jpg',\n",
       " 'img_100264.jpg',\n",
       " 'img_100265.jpg',\n",
       " 'img_100266.jpg',\n",
       " 'img_100267.jpg',\n",
       " 'img_100268.jpg',\n",
       " 'img_100269.jpg',\n",
       " 'img_10027.jpg',\n",
       " 'img_100271.jpg',\n",
       " 'img_100272.jpg',\n",
       " 'img_100273.jpg',\n",
       " 'img_100274.jpg',\n",
       " 'img_100275.jpg',\n",
       " 'img_100276.jpg',\n",
       " 'img_100278.jpg',\n",
       " 'img_100279.jpg',\n",
       " 'img_10028.jpg',\n",
       " 'img_100280.jpg',\n",
       " 'img_100282.jpg',\n",
       " 'img_100283.jpg',\n",
       " 'img_100284.jpg',\n",
       " 'img_100287.jpg',\n",
       " 'img_100288.jpg',\n",
       " 'img_100289.jpg',\n",
       " 'img_10029.jpg',\n",
       " 'img_100290.jpg',\n",
       " 'img_100291.jpg',\n",
       " 'img_100292.jpg',\n",
       " 'img_100293.jpg',\n",
       " 'img_100296.jpg',\n",
       " 'img_100298.jpg',\n",
       " 'img_1003.jpg',\n",
       " 'img_10030.jpg',\n",
       " 'img_100300.jpg',\n",
       " 'img_100301.jpg',\n",
       " 'img_100302.jpg',\n",
       " 'img_100303.jpg',\n",
       " 'img_100304.jpg',\n",
       " 'img_100305.jpg',\n",
       " 'img_100306.jpg',\n",
       " 'img_100307.jpg',\n",
       " 'img_100308.jpg',\n",
       " 'img_10031.jpg',\n",
       " 'img_100310.jpg',\n",
       " 'img_100311.jpg',\n",
       " 'img_100313.jpg',\n",
       " 'img_100315.jpg',\n",
       " 'img_100316.jpg',\n",
       " 'img_100317.jpg',\n",
       " 'img_100318.jpg',\n",
       " 'img_100319.jpg',\n",
       " 'img_10032.jpg',\n",
       " 'img_100320.jpg',\n",
       " 'img_100321.jpg',\n",
       " 'img_100322.jpg',\n",
       " 'img_100323.jpg',\n",
       " 'img_100324.jpg',\n",
       " 'img_100325.jpg',\n",
       " 'img_100326.jpg',\n",
       " 'img_100329.jpg',\n",
       " 'img_10033.jpg',\n",
       " 'img_100330.jpg',\n",
       " 'img_100331.jpg',\n",
       " 'img_100332.jpg',\n",
       " 'img_100333.jpg',\n",
       " 'img_100335.jpg',\n",
       " 'img_100338.jpg',\n",
       " 'img_100340.jpg',\n",
       " 'img_100341.jpg',\n",
       " 'img_100342.jpg',\n",
       " 'img_100344.jpg',\n",
       " 'img_100345.jpg',\n",
       " 'img_100346.jpg',\n",
       " 'img_100349.jpg',\n",
       " 'img_10035.jpg',\n",
       " 'img_100350.jpg',\n",
       " 'img_100351.jpg',\n",
       " 'img_100353.jpg',\n",
       " 'img_100354.jpg',\n",
       " 'img_100355.jpg',\n",
       " 'img_100356.jpg',\n",
       " 'img_100357.jpg',\n",
       " 'img_100359.jpg',\n",
       " 'img_10036.jpg',\n",
       " 'img_100360.jpg',\n",
       " 'img_100362.jpg',\n",
       " 'img_100363.jpg',\n",
       " 'img_100366.jpg',\n",
       " 'img_100367.jpg',\n",
       " 'img_100369.jpg',\n",
       " 'img_10037.jpg',\n",
       " 'img_100370.jpg',\n",
       " 'img_100372.jpg',\n",
       " 'img_100373.jpg',\n",
       " 'img_100376.jpg',\n",
       " 'img_100377.jpg',\n",
       " 'img_100378.jpg',\n",
       " 'img_10038.jpg',\n",
       " 'img_100380.jpg',\n",
       " 'img_100381.jpg',\n",
       " 'img_100382.jpg',\n",
       " 'img_100383.jpg',\n",
       " 'img_100384.jpg',\n",
       " 'img_100385.jpg',\n",
       " 'img_100386.jpg',\n",
       " 'img_100387.jpg',\n",
       " 'img_100388.jpg',\n",
       " 'img_100389.jpg',\n",
       " 'img_100390.jpg',\n",
       " 'img_100391.jpg',\n",
       " 'img_100392.jpg',\n",
       " 'img_100395.jpg',\n",
       " 'img_100397.jpg',\n",
       " 'img_100398.jpg',\n",
       " 'img_1004.jpg',\n",
       " 'img_10040.jpg',\n",
       " 'img_100400.jpg',\n",
       " 'img_100401.jpg',\n",
       " 'img_100402.jpg',\n",
       " 'img_100404.jpg',\n",
       " 'img_100405.jpg',\n",
       " 'img_100406.jpg',\n",
       " 'img_100407.jpg',\n",
       " 'img_100409.jpg',\n",
       " 'img_10041.jpg',\n",
       " 'img_100410.jpg',\n",
       " 'img_100411.jpg',\n",
       " 'img_100413.jpg',\n",
       " 'img_100415.jpg',\n",
       " 'img_100416.jpg',\n",
       " 'img_100417.jpg',\n",
       " 'img_100418.jpg',\n",
       " 'img_10042.jpg',\n",
       " 'img_100420.jpg',\n",
       " 'img_100422.jpg',\n",
       " 'img_100424.jpg',\n",
       " 'img_100425.jpg',\n",
       " 'img_100426.jpg',\n",
       " 'img_100427.jpg',\n",
       " 'img_10043.jpg',\n",
       " 'img_100430.jpg',\n",
       " 'img_100432.jpg',\n",
       " 'img_100433.jpg',\n",
       " 'img_100434.jpg',\n",
       " 'img_100435.jpg',\n",
       " 'img_100436.jpg',\n",
       " 'img_100437.jpg',\n",
       " 'img_100438.jpg',\n",
       " 'img_100439.jpg',\n",
       " 'img_10044.jpg',\n",
       " 'img_100440.jpg',\n",
       " 'img_100441.jpg',\n",
       " 'img_100443.jpg',\n",
       " 'img_100444.jpg',\n",
       " 'img_100445.jpg',\n",
       " 'img_100447.jpg',\n",
       " 'img_100448.jpg',\n",
       " 'img_100449.jpg',\n",
       " 'img_10045.jpg',\n",
       " 'img_100450.jpg',\n",
       " 'img_100453.jpg',\n",
       " 'img_100454.jpg',\n",
       " 'img_100457.jpg',\n",
       " 'img_100459.jpg',\n",
       " 'img_100461.jpg',\n",
       " 'img_100462.jpg',\n",
       " 'img_100463.jpg',\n",
       " 'img_100464.jpg',\n",
       " 'img_100465.jpg',\n",
       " 'img_100466.jpg',\n",
       " 'img_100468.jpg',\n",
       " 'img_10047.jpg',\n",
       " 'img_100470.jpg',\n",
       " 'img_100473.jpg',\n",
       " 'img_100474.jpg',\n",
       " 'img_100475.jpg',\n",
       " 'img_100476.jpg',\n",
       " 'img_100477.jpg',\n",
       " 'img_100478.jpg',\n",
       " 'img_100479.jpg',\n",
       " 'img_100481.jpg',\n",
       " 'img_100482.jpg',\n",
       " 'img_100483.jpg',\n",
       " 'img_100484.jpg',\n",
       " 'img_100485.jpg',\n",
       " 'img_100486.jpg',\n",
       " 'img_100487.jpg',\n",
       " 'img_100488.jpg',\n",
       " 'img_100489.jpg',\n",
       " 'img_10049.jpg',\n",
       " 'img_100490.jpg',\n",
       " 'img_100491.jpg',\n",
       " 'img_100492.jpg',\n",
       " 'img_100494.jpg',\n",
       " 'img_100495.jpg',\n",
       " 'img_100496.jpg',\n",
       " 'img_100497.jpg',\n",
       " 'img_100498.jpg',\n",
       " 'img_100500.jpg',\n",
       " 'img_100501.jpg',\n",
       " 'img_100504.jpg',\n",
       " 'img_100505.jpg',\n",
       " 'img_100506.jpg',\n",
       " 'img_100507.jpg',\n",
       " 'img_100508.jpg',\n",
       " 'img_100509.jpg',\n",
       " 'img_10051.jpg',\n",
       " 'img_100510.jpg',\n",
       " 'img_100511.jpg',\n",
       " 'img_100512.jpg',\n",
       " 'img_100513.jpg',\n",
       " 'img_100516.jpg',\n",
       " 'img_100517.jpg',\n",
       " 'img_100518.jpg',\n",
       " 'img_100519.jpg',\n",
       " 'img_100520.jpg',\n",
       " 'img_100521.jpg',\n",
       " 'img_100522.jpg',\n",
       " 'img_100523.jpg',\n",
       " 'img_100524.jpg',\n",
       " 'img_100525.jpg',\n",
       " 'img_100526.jpg',\n",
       " 'img_100527.jpg',\n",
       " 'img_100531.jpg',\n",
       " 'img_100532.jpg',\n",
       " 'img_100533.jpg',\n",
       " 'img_100534.jpg',\n",
       " 'img_100535.jpg',\n",
       " 'img_100536.jpg',\n",
       " 'img_100537.jpg',\n",
       " 'img_100538.jpg',\n",
       " 'img_100539.jpg',\n",
       " 'img_10054.jpg',\n",
       " 'img_100541.jpg',\n",
       " 'img_100543.jpg',\n",
       " 'img_100544.jpg',\n",
       " 'img_100546.jpg',\n",
       " 'img_100547.jpg',\n",
       " 'img_100549.jpg',\n",
       " 'img_10055.jpg',\n",
       " 'img_100550.jpg',\n",
       " 'img_100551.jpg',\n",
       " 'img_100552.jpg',\n",
       " 'img_100553.jpg',\n",
       " 'img_100554.jpg',\n",
       " 'img_100555.jpg',\n",
       " 'img_100557.jpg',\n",
       " 'img_100558.jpg',\n",
       " 'img_100559.jpg',\n",
       " 'img_10056.jpg',\n",
       " 'img_100560.jpg',\n",
       " 'img_100562.jpg',\n",
       " 'img_100563.jpg',\n",
       " 'img_100564.jpg',\n",
       " 'img_100566.jpg',\n",
       " 'img_100567.jpg',\n",
       " 'img_100569.jpg',\n",
       " 'img_10057.jpg',\n",
       " 'img_100570.jpg',\n",
       " 'img_100571.jpg',\n",
       " 'img_100572.jpg',\n",
       " 'img_100573.jpg',\n",
       " 'img_100574.jpg',\n",
       " 'img_100575.jpg',\n",
       " 'img_100576.jpg',\n",
       " 'img_100577.jpg',\n",
       " 'img_100578.jpg',\n",
       " 'img_10058.jpg',\n",
       " 'img_100580.jpg',\n",
       " 'img_100581.jpg',\n",
       " 'img_100582.jpg',\n",
       " 'img_100583.jpg',\n",
       " 'img_100584.jpg',\n",
       " 'img_100585.jpg',\n",
       " 'img_100586.jpg',\n",
       " 'img_100587.jpg',\n",
       " 'img_100588.jpg',\n",
       " 'img_10059.jpg',\n",
       " 'img_100590.jpg',\n",
       " 'img_100591.jpg',\n",
       " 'img_100592.jpg',\n",
       " 'img_100593.jpg',\n",
       " 'img_100595.jpg',\n",
       " 'img_100596.jpg',\n",
       " 'img_100597.jpg',\n",
       " 'img_100599.jpg',\n",
       " 'img_1006.jpg',\n",
       " 'img_10060.jpg',\n",
       " 'img_100600.jpg',\n",
       " 'img_100601.jpg',\n",
       " 'img_100602.jpg',\n",
       " 'img_100603.jpg',\n",
       " 'img_100604.jpg',\n",
       " 'img_100606.jpg',\n",
       " 'img_100607.jpg',\n",
       " 'img_100608.jpg',\n",
       " 'img_100609.jpg',\n",
       " 'img_10061.jpg',\n",
       " 'img_100610.jpg',\n",
       " 'img_100612.jpg',\n",
       " 'img_100613.jpg',\n",
       " 'img_100614.jpg',\n",
       " 'img_100615.jpg',\n",
       " 'img_100616.jpg',\n",
       " 'img_100617.jpg',\n",
       " 'img_100618.jpg',\n",
       " 'img_100619.jpg',\n",
       " 'img_100620.jpg',\n",
       " 'img_100621.jpg',\n",
       " 'img_100622.jpg',\n",
       " 'img_100623.jpg',\n",
       " 'img_100624.jpg',\n",
       " 'img_100625.jpg',\n",
       " 'img_100626.jpg',\n",
       " 'img_100628.jpg',\n",
       " 'img_100629.jpg',\n",
       " 'img_10063.jpg',\n",
       " 'img_100630.jpg',\n",
       " 'img_100631.jpg',\n",
       " 'img_100632.jpg',\n",
       " 'img_100633.jpg',\n",
       " 'img_100635.jpg',\n",
       " 'img_100637.jpg',\n",
       " 'img_100639.jpg',\n",
       " 'img_10064.jpg',\n",
       " 'img_100641.jpg',\n",
       " 'img_100642.jpg',\n",
       " 'img_100644.jpg',\n",
       " 'img_100645.jpg',\n",
       " 'img_100647.jpg',\n",
       " 'img_100648.jpg',\n",
       " 'img_100649.jpg',\n",
       " 'img_10065.jpg',\n",
       " 'img_100650.jpg',\n",
       " 'img_100651.jpg',\n",
       " 'img_100652.jpg',\n",
       " 'img_100653.jpg',\n",
       " 'img_100654.jpg',\n",
       " 'img_100655.jpg',\n",
       " 'img_100657.jpg',\n",
       " 'img_100658.jpg',\n",
       " 'img_100659.jpg',\n",
       " 'img_10066.jpg',\n",
       " 'img_100660.jpg',\n",
       " 'img_100661.jpg',\n",
       " 'img_100662.jpg',\n",
       " 'img_100663.jpg',\n",
       " 'img_100666.jpg',\n",
       " 'img_100667.jpg',\n",
       " 'img_100668.jpg',\n",
       " 'img_100669.jpg',\n",
       " 'img_10067.jpg',\n",
       " 'img_100670.jpg',\n",
       " 'img_100671.jpg',\n",
       " 'img_100672.jpg',\n",
       " 'img_100673.jpg',\n",
       " 'img_100674.jpg',\n",
       " 'img_100675.jpg',\n",
       " 'img_100677.jpg',\n",
       " 'img_100678.jpg',\n",
       " 'img_100679.jpg',\n",
       " 'img_100680.jpg',\n",
       " 'img_100681.jpg',\n",
       " 'img_100684.jpg',\n",
       " 'img_100685.jpg',\n",
       " 'img_100686.jpg',\n",
       " 'img_100687.jpg',\n",
       " 'img_10069.jpg',\n",
       " 'img_100692.jpg',\n",
       " 'img_100694.jpg',\n",
       " 'img_100696.jpg',\n",
       " 'img_100698.jpg',\n",
       " 'img_100699.jpg',\n",
       " 'img_1007.jpg',\n",
       " 'img_10070.jpg',\n",
       " 'img_100700.jpg',\n",
       " 'img_100703.jpg',\n",
       " 'img_100704.jpg',\n",
       " 'img_100705.jpg',\n",
       " 'img_100707.jpg',\n",
       " 'img_100708.jpg',\n",
       " 'img_100709.jpg',\n",
       " 'img_10071.jpg',\n",
       " 'img_100710.jpg',\n",
       " 'img_100711.jpg',\n",
       " 'img_100712.jpg',\n",
       " 'img_100713.jpg',\n",
       " 'img_100714.jpg',\n",
       " 'img_100716.jpg',\n",
       " 'img_100717.jpg',\n",
       " 'img_100718.jpg',\n",
       " 'img_100719.jpg',\n",
       " 'img_10072.jpg',\n",
       " 'img_100720.jpg',\n",
       " 'img_100721.jpg',\n",
       " 'img_100722.jpg',\n",
       " 'img_100723.jpg',\n",
       " 'img_100724.jpg',\n",
       " 'img_100725.jpg',\n",
       " 'img_100726.jpg',\n",
       " 'img_100727.jpg',\n",
       " 'img_100728.jpg',\n",
       " 'img_10073.jpg',\n",
       " 'img_100730.jpg',\n",
       " 'img_100731.jpg',\n",
       " 'img_100732.jpg',\n",
       " 'img_100733.jpg',\n",
       " 'img_100734.jpg',\n",
       " 'img_100736.jpg',\n",
       " 'img_100737.jpg',\n",
       " 'img_100739.jpg',\n",
       " 'img_10074.jpg',\n",
       " 'img_100740.jpg',\n",
       " 'img_100741.jpg',\n",
       " 'img_100742.jpg',\n",
       " 'img_100744.jpg',\n",
       " 'img_100745.jpg',\n",
       " 'img_100746.jpg',\n",
       " 'img_100747.jpg',\n",
       " 'img_100748.jpg',\n",
       " 'img_10075.jpg',\n",
       " 'img_100750.jpg',\n",
       " 'img_100751.jpg',\n",
       " 'img_100752.jpg',\n",
       " 'img_100753.jpg',\n",
       " 'img_100755.jpg',\n",
       " 'img_100756.jpg',\n",
       " 'img_100757.jpg',\n",
       " 'img_100758.jpg',\n",
       " 'img_100759.jpg',\n",
       " 'img_10076.jpg',\n",
       " 'img_100760.jpg',\n",
       " 'img_100761.jpg',\n",
       " 'img_100763.jpg',\n",
       " 'img_100764.jpg',\n",
       " 'img_100765.jpg',\n",
       " 'img_100766.jpg',\n",
       " 'img_100767.jpg',\n",
       " 'img_100768.jpg',\n",
       " 'img_100769.jpg',\n",
       " 'img_10077.jpg',\n",
       " 'img_100770.jpg',\n",
       " 'img_100771.jpg',\n",
       " 'img_100772.jpg',\n",
       " 'img_100773.jpg',\n",
       " 'img_100774.jpg',\n",
       " 'img_100775.jpg',\n",
       " 'img_100779.jpg',\n",
       " 'img_100780.jpg',\n",
       " 'img_100781.jpg',\n",
       " 'img_100782.jpg',\n",
       " 'img_100785.jpg',\n",
       " 'img_100786.jpg',\n",
       " 'img_100788.jpg',\n",
       " 'img_100789.jpg',\n",
       " 'img_10079.jpg',\n",
       " 'img_100790.jpg',\n",
       " 'img_100792.jpg',\n",
       " 'img_100793.jpg',\n",
       " 'img_100794.jpg',\n",
       " 'img_100795.jpg',\n",
       " 'img_100798.jpg',\n",
       " 'img_100799.jpg',\n",
       " 'img_1008.jpg',\n",
       " 'img_100800.jpg',\n",
       " 'img_100801.jpg',\n",
       " 'img_100802.jpg',\n",
       " 'img_100803.jpg',\n",
       " 'img_100804.jpg',\n",
       " 'img_100805.jpg',\n",
       " 'img_100806.jpg',\n",
       " 'img_100807.jpg',\n",
       " 'img_100809.jpg',\n",
       " 'img_10081.jpg',\n",
       " 'img_100810.jpg',\n",
       " 'img_100812.jpg',\n",
       " 'img_100815.jpg',\n",
       " 'img_100817.jpg',\n",
       " 'img_100819.jpg',\n",
       " 'img_10082.jpg',\n",
       " 'img_100820.jpg',\n",
       " 'img_100822.jpg',\n",
       " 'img_100826.jpg',\n",
       " 'img_100827.jpg',\n",
       " 'img_100829.jpg',\n",
       " 'img_10083.jpg',\n",
       " 'img_100831.jpg',\n",
       " 'img_100832.jpg',\n",
       " 'img_100833.jpg',\n",
       " 'img_100834.jpg',\n",
       " 'img_100835.jpg',\n",
       " 'img_100836.jpg',\n",
       " 'img_100839.jpg',\n",
       " 'img_10084.jpg',\n",
       " 'img_100840.jpg',\n",
       " 'img_100841.jpg',\n",
       " 'img_100842.jpg',\n",
       " 'img_100843.jpg',\n",
       " 'img_100844.jpg',\n",
       " 'img_100845.jpg',\n",
       " 'img_100847.jpg',\n",
       " 'img_100848.jpg',\n",
       " 'img_100849.jpg',\n",
       " 'img_10085.jpg',\n",
       " 'img_100851.jpg',\n",
       " 'img_100852.jpg',\n",
       " 'img_100853.jpg',\n",
       " 'img_100854.jpg',\n",
       " 'img_100855.jpg',\n",
       " 'img_100856.jpg',\n",
       " 'img_100857.jpg',\n",
       " 'img_100858.jpg',\n",
       " 'img_100859.jpg',\n",
       " 'img_10086.jpg',\n",
       " 'img_100860.jpg',\n",
       " 'img_100861.jpg',\n",
       " 'img_100862.jpg',\n",
       " 'img_100863.jpg',\n",
       " 'img_100864.jpg',\n",
       " 'img_100865.jpg',\n",
       " 'img_100866.jpg',\n",
       " 'img_100867.jpg',\n",
       " 'img_100868.jpg',\n",
       " 'img_100869.jpg',\n",
       " 'img_10087.jpg',\n",
       " 'img_100873.jpg',\n",
       " 'img_100874.jpg',\n",
       " 'img_100875.jpg',\n",
       " 'img_100876.jpg',\n",
       " 'img_100877.jpg',\n",
       " 'img_100878.jpg',\n",
       " 'img_100879.jpg',\n",
       " 'img_10088.jpg',\n",
       " 'img_100880.jpg',\n",
       " 'img_100881.jpg',\n",
       " 'img_100883.jpg',\n",
       " 'img_100884.jpg',\n",
       " 'img_100885.jpg',\n",
       " 'img_100886.jpg',\n",
       " 'img_100887.jpg',\n",
       " 'img_100888.jpg',\n",
       " 'img_100889.jpg',\n",
       " 'img_10089.jpg',\n",
       " 'img_100890.jpg',\n",
       " 'img_100891.jpg',\n",
       " 'img_100892.jpg',\n",
       " 'img_100893.jpg',\n",
       " 'img_100894.jpg',\n",
       " 'img_100895.jpg',\n",
       " 'img_100896.jpg',\n",
       " 'img_100898.jpg',\n",
       " 'img_100899.jpg',\n",
       " 'img_1009.jpg',\n",
       " 'img_100900.jpg',\n",
       " 'img_100901.jpg',\n",
       " 'img_100902.jpg',\n",
       " 'img_100903.jpg',\n",
       " 'img_100904.jpg',\n",
       " 'img_100906.jpg',\n",
       " 'img_100907.jpg',\n",
       " 'img_100908.jpg',\n",
       " 'img_100909.jpg',\n",
       " 'img_10091.jpg',\n",
       " 'img_100910.jpg',\n",
       " 'img_100911.jpg',\n",
       " 'img_100914.jpg',\n",
       " 'img_100916.jpg',\n",
       " 'img_100917.jpg',\n",
       " 'img_100918.jpg',\n",
       " 'img_100919.jpg',\n",
       " 'img_100920.jpg',\n",
       " 'img_100921.jpg',\n",
       " 'img_100923.jpg',\n",
       " 'img_100924.jpg',\n",
       " 'img_100925.jpg',\n",
       " 'img_100926.jpg',\n",
       " 'img_100928.jpg',\n",
       " 'img_100929.jpg',\n",
       " 'img_100930.jpg',\n",
       " 'img_100931.jpg',\n",
       " 'img_100933.jpg',\n",
       " 'img_100934.jpg',\n",
       " 'img_100935.jpg',\n",
       " 'img_100936.jpg',\n",
       " 'img_100937.jpg',\n",
       " 'img_100938.jpg',\n",
       " 'img_100940.jpg',\n",
       " 'img_100941.jpg',\n",
       " 'img_100942.jpg',\n",
       " 'img_100943.jpg',\n",
       " 'img_100944.jpg',\n",
       " 'img_100945.jpg',\n",
       " 'img_100946.jpg',\n",
       " 'img_100947.jpg',\n",
       " 'img_100948.jpg',\n",
       " 'img_100949.jpg',\n",
       " 'img_10095.jpg',\n",
       " 'img_100950.jpg',\n",
       " 'img_100951.jpg',\n",
       " 'img_100952.jpg',\n",
       " 'img_100953.jpg',\n",
       " 'img_100954.jpg',\n",
       " 'img_100955.jpg',\n",
       " 'img_100956.jpg',\n",
       " 'img_100957.jpg',\n",
       " 'img_100958.jpg',\n",
       " 'img_100959.jpg',\n",
       " 'img_100960.jpg',\n",
       " 'img_100962.jpg',\n",
       " 'img_100963.jpg',\n",
       " 'img_100964.jpg',\n",
       " 'img_100965.jpg',\n",
       " 'img_100966.jpg',\n",
       " 'img_100967.jpg',\n",
       " 'img_100968.jpg',\n",
       " 'img_100969.jpg',\n",
       " 'img_10097.jpg',\n",
       " 'img_100970.jpg',\n",
       " 'img_100971.jpg',\n",
       " 'img_100972.jpg',\n",
       " 'img_100973.jpg',\n",
       " 'img_100974.jpg',\n",
       " 'img_100975.jpg',\n",
       " 'img_100977.jpg',\n",
       " 'img_100978.jpg',\n",
       " 'img_10098.jpg',\n",
       " 'img_100980.jpg',\n",
       " 'img_100981.jpg',\n",
       " 'img_100982.jpg',\n",
       " 'img_100983.jpg',\n",
       " 'img_100984.jpg',\n",
       " 'img_100985.jpg',\n",
       " 'img_100986.jpg',\n",
       " 'img_100987.jpg',\n",
       " 'img_100988.jpg',\n",
       " 'img_100989.jpg',\n",
       " 'img_10099.jpg',\n",
       " 'img_100990.jpg',\n",
       " 'img_100991.jpg',\n",
       " 'img_100992.jpg',\n",
       " 'img_100994.jpg',\n",
       " 'img_100996.jpg',\n",
       " 'img_100997.jpg',\n",
       " 'img_100998.jpg',\n",
       " 'img_100999.jpg',\n",
       " 'img_101.jpg',\n",
       " 'img_10100.jpg',\n",
       " 'img_101000.jpg',\n",
       " 'img_101001.jpg',\n",
       " 'img_101002.jpg',\n",
       " 'img_101003.jpg',\n",
       " 'img_101004.jpg',\n",
       " 'img_101005.jpg',\n",
       " 'img_101006.jpg',\n",
       " 'img_101007.jpg',\n",
       " 'img_101008.jpg',\n",
       " 'img_101009.jpg',\n",
       " 'img_10101.jpg',\n",
       " 'img_101010.jpg',\n",
       " 'img_101012.jpg',\n",
       " 'img_101013.jpg',\n",
       " 'img_101017.jpg',\n",
       " 'img_101019.jpg',\n",
       " 'img_101020.jpg',\n",
       " 'img_101022.jpg',\n",
       " 'img_101024.jpg',\n",
       " 'img_101025.jpg',\n",
       " 'img_101026.jpg',\n",
       " 'img_101027.jpg',\n",
       " 'img_101028.jpg',\n",
       " 'img_101031.jpg',\n",
       " 'img_101036.jpg',\n",
       " 'img_101037.jpg',\n",
       " 'img_101039.jpg',\n",
       " 'img_10104.jpg',\n",
       " 'img_101040.jpg',\n",
       " 'img_101041.jpg',\n",
       " 'img_101042.jpg',\n",
       " 'img_101043.jpg',\n",
       " 'img_101044.jpg',\n",
       " 'img_101045.jpg',\n",
       " 'img_101046.jpg',\n",
       " 'img_101048.jpg',\n",
       " 'img_101049.jpg',\n",
       " 'img_10105.jpg',\n",
       " 'img_101050.jpg',\n",
       " 'img_101052.jpg',\n",
       " 'img_101053.jpg',\n",
       " 'img_101054.jpg',\n",
       " 'img_101055.jpg',\n",
       " 'img_101056.jpg',\n",
       " 'img_101057.jpg',\n",
       " 'img_101058.jpg',\n",
       " 'img_10106.jpg',\n",
       " 'img_101060.jpg',\n",
       " 'img_101061.jpg',\n",
       " 'img_101062.jpg',\n",
       " 'img_101064.jpg',\n",
       " 'img_101067.jpg',\n",
       " 'img_101069.jpg',\n",
       " 'img_10107.jpg',\n",
       " 'img_101070.jpg',\n",
       " 'img_101071.jpg',\n",
       " 'img_101072.jpg',\n",
       " 'img_101073.jpg',\n",
       " 'img_101074.jpg',\n",
       " 'img_101076.jpg',\n",
       " 'img_101080.jpg',\n",
       " 'img_101081.jpg',\n",
       " 'img_101082.jpg',\n",
       " 'img_101083.jpg',\n",
       " 'img_101084.jpg',\n",
       " 'img_101085.jpg',\n",
       " 'img_101089.jpg',\n",
       " 'img_10109.jpg',\n",
       " 'img_101090.jpg',\n",
       " 'img_101092.jpg',\n",
       " 'img_101094.jpg',\n",
       " 'img_101095.jpg',\n",
       " 'img_101098.jpg',\n",
       " 'img_101099.jpg',\n",
       " 'img_1011.jpg',\n",
       " 'img_10110.jpg',\n",
       " 'img_101100.jpg',\n",
       " 'img_101101.jpg',\n",
       " 'img_101103.jpg',\n",
       " 'img_101104.jpg',\n",
       " 'img_101105.jpg',\n",
       " 'img_101106.jpg',\n",
       " 'img_101108.jpg',\n",
       " 'img_101109.jpg',\n",
       " 'img_10111.jpg',\n",
       " 'img_101111.jpg',\n",
       " 'img_101112.jpg',\n",
       " 'img_101114.jpg',\n",
       " 'img_101115.jpg',\n",
       " 'img_101116.jpg',\n",
       " 'img_101117.jpg',\n",
       " 'img_101119.jpg',\n",
       " 'img_10112.jpg',\n",
       " 'img_101120.jpg',\n",
       " 'img_101121.jpg',\n",
       " 'img_101124.jpg',\n",
       " 'img_101125.jpg',\n",
       " 'img_101126.jpg',\n",
       " 'img_101127.jpg',\n",
       " 'img_101128.jpg',\n",
       " 'img_101129.jpg',\n",
       " 'img_10113.jpg',\n",
       " 'img_101131.jpg',\n",
       " 'img_101132.jpg',\n",
       " 'img_101133.jpg',\n",
       " 'img_101135.jpg',\n",
       " 'img_101137.jpg',\n",
       " 'img_101138.jpg',\n",
       " 'img_101139.jpg',\n",
       " 'img_10114.jpg',\n",
       " 'img_101140.jpg',\n",
       " 'img_101141.jpg',\n",
       " 'img_101142.jpg',\n",
       " 'img_101143.jpg',\n",
       " 'img_101145.jpg',\n",
       " 'img_101146.jpg',\n",
       " ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " [a[8:] for a in test_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T08:03:13.211348Z",
     "start_time": "2018-07-28T08:03:13.187356Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>c0</th>\n",
       "      <th>c1</th>\n",
       "      <th>c2</th>\n",
       "      <th>c3</th>\n",
       "      <th>c4</th>\n",
       "      <th>c5</th>\n",
       "      <th>c6</th>\n",
       "      <th>c7</th>\n",
       "      <th>c8</th>\n",
       "      <th>c9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_1.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_10.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_100.jpg</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_1000.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_100000.jpg</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.042645</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              img        c0        c1        c2        c3        c4        c5  \\\n",
       "0       img_1.jpg  0.007778  0.007778  0.007778  0.007778  0.007778  0.930000   \n",
       "1      img_10.jpg  0.007778  0.007778  0.007778  0.007778  0.007778  0.930000   \n",
       "2     img_100.jpg  0.930000  0.007778  0.007778  0.007778  0.007778  0.007778   \n",
       "3    img_1000.jpg  0.007778  0.007778  0.007778  0.007778  0.007778  0.007778   \n",
       "4  img_100000.jpg  0.007778  0.007778  0.007778  0.930000  0.007778  0.007778   \n",
       "\n",
       "         c6        c7        c8        c9  \n",
       "0  0.007778  0.007778  0.007778  0.007778  \n",
       "1  0.007778  0.007778  0.007778  0.007778  \n",
       "2  0.007778  0.007778  0.007778  0.007778  \n",
       "3  0.007778  0.007778  0.930000  0.007778  \n",
       "4  0.007778  0.007778  0.042645  0.007778  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(subm, columns=classes)\n",
    "submission.insert(0, 'img', [a[8:] for a in test_filenames])\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T08:03:15.037775Z",
     "start_time": "2018-07-28T08:03:13.212347Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv(subm_name, index=False, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-28T08:03:15.044761Z",
     "start_time": "2018-07-28T08:03:15.039763Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='data/state/results/subm.gz' target='_blank'>data/state/results/subm.gz</a><br>"
      ],
      "text/plain": [
       "D:\\ML\\courses\\deeplearning1\\nbs\\data\\state\\results\\subm.gz"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FileLink(subm_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gets 0.534 on the leaderboard."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nav_menu": {},
  "nbpresent": {
   "slides": {
    "28b43202-5690-4169-9aca-6b9dabfeb3ec": {
     "id": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "prev": null,
     "regions": {
      "3bba644a-cf4d-4a49-9fbd-e2554428cf9f": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f3d3a388-7e2a-4151-9b50-c20498fceacc",
        "part": "whole"
       },
       "id": "3bba644a-cf4d-4a49-9fbd-e2554428cf9f"
      }
     }
    },
    "8104def2-4b68-44a0-8f1b-b03bf3b2a079": {
     "id": "8104def2-4b68-44a0-8f1b-b03bf3b2a079",
     "prev": "28b43202-5690-4169-9aca-6b9dabfeb3ec",
     "regions": {
      "7dded777-1ddf-4100-99ae-25cf1c15b575": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fe47bd48-3414-4657-92e7-8b8d6cb0df00",
        "part": "whole"
       },
       "id": "7dded777-1ddf-4100-99ae-25cf1c15b575"
      }
     }
    }
   },
   "themes": {}
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "148px",
    "width": "254px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "578px",
    "left": "292px",
    "top": "218.8px",
    "width": "212px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
